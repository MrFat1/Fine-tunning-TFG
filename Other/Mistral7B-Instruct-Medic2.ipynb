{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5a6f583-2990-41af-a203-ce7745438c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pandas\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install -q transformers\n",
    "!pip install -q datasets\n",
    "!pip install -q git+https://github.com/huggingface/peft.git\n",
    "!pip install -q bitsandbytes\n",
    "!pip install -q trl\n",
    "!pip install -q tensorboardX\n",
    "!pip install -q wandb -U\n",
    "!pip install -q -U matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b74619e4-24f4-440a-bc96-a9fc810c5c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Copy-and-paste the text below in your GitHub issue and FILL OUT the two last points.\n",
      "\n",
      "- `transformers` version: 4.40.1\n",
      "- Platform: Windows-10-10.0.22621-SP0\n",
      "- Python version: 3.11.9\n",
      "- Huggingface_hub version: 0.22.2\n",
      "- Safetensors version: 0.4.3\n",
      "- Accelerate version: 0.29.3\n",
      "- Accelerate config: \tnot found\n",
      "- PyTorch version (GPU?): 2.3.0+cu121 (True)\n",
      "- Tensorflow version (GPU?): not installed (NA)\n",
      "- Flax version (CPU?/GPU?/TPU?): not installed (NA)\n",
      "- Jax version: not installed\n",
      "- JaxLib version: not installed\n",
      "- Using GPU in script?: <fill in>\n",
      "- Using distributed or parallel set-up in script?: <fill in>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!transformers-cli env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c8d8796-5f4d-4aaa-9627-d029d2dd23b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Tue_Aug_15_22:09:35_Pacific_Daylight_Time_2023\n",
      "Cuda compilation tools, release 12.2, V12.2.140\n",
      "Build cuda_12.2.r12.2/compiler.33191640_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "394c68ab-9bb8-4094-a192-cb806492d486",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q ipywidgets\n",
    "!pip install -q huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "223b6592-c4ff-4ea5-945f-77f26886a478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad4619387f3345d58f4256a929ccd8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Log in to the HugginFace Model Hub\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcd0ceb-679e-4912-ad4c-058dfe4dacbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10ebe4c-6fd8-4e6c-864a-8eba0cb31f60",
   "metadata": {},
   "source": [
    "## Prueba del modelo base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dd1aa6e-9ccc-4a2a-8bb1-7133967827a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\201902452\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from peft import LoraConfig, PeftModel\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from trl import SFTTrainer\n",
    "import accelerate\n",
    "import tensorboardX\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "273d8210-03da-47cd-8a09-89226167022d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\201902452\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\201902452\\.cache\\huggingface\\hub\\models--mistralai--Mistral-7B-Instruct-v0.2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# Base Model (HuggingFace path)\n",
    "base_model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "# Load MitsralAi tokenizer for dataset formatting\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "#tokenizer.pad_token = tokenizer.eos_token\n",
    "#tokenizer.padding_side = \"left\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    trust_remote_code=True,\n",
    "    padding_side=\"right\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fd2caf-37b0-4bb7-975a-8c0f9128e84e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c3afd44-8c39-4d4d-a730-f029ded9d40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros del modelo\n",
    "\n",
    "# Fine-tunned model name\n",
    "fine_tuned_model = \"MrFat/mistral7b_medic\"\n",
    "\n",
    "# Dataset name\n",
    "dataset_name = \"medalpaca/medical_meadow_wikidoc\"\n",
    "\n",
    "######### QLORA Params #############\n",
    "# (Para reducir el uso de memoria)\n",
    "\n",
    "# Estos valores dependen del dataset\n",
    "# The rank of the low-rank matrix used in the adapters, which thus controls the number of parameters trained. \n",
    "# A higher rank will allow for more expressivity, but there is a compute tradeoff. (2^x)\n",
    "lora_r = 32\n",
    "\n",
    "# Scaling factor for the learned weights. The weight matrix is scaled by alpha/r, and thus a higher value for alpha assigns more weight to \n",
    "# the LoRA activations.\n",
    "lora_alpha = 64\n",
    "\n",
    "# NOTA: En el paper de QLoRA utiliza los valoes de r = 64 y alpha = 16, argumentando que estos valores generalizan bastante bien. Si queremos darle mas\n",
    "# importancia a la data fine-tuneada aumentamos los valores de alpha y si queremos mejor rendimiento disminuimos R.\n",
    "\n",
    "# Dropout probability\n",
    "# Durante el entranmiento, en cada epoch hay un {lora_dropout}% de que las neuronas se desactiven (para que trabaje mas)\n",
    "lora_dropout = 0.1\n",
    "\n",
    "####### BitsAndBytes param ###########\n",
    "\n",
    "#Activamos la reducción de precisión a 4-bit\n",
    "use_4bit = True\n",
    "\n",
    "# Parámetro para los modelos 4-bit\n",
    "bnb_4bit_compute_dtype = \"bfloat16\" #torch.float16 != torch.bfloat16\n",
    "\n",
    "# Tipo de cuantización (fp4 o nf4)\n",
    "# nf4 utiliza una distribución normal\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Nested quantization for 4-bit base models (double quantization)\n",
    "# Nos proporciona una mayor eficiencia de memoria sin sacrificiar rendimiento. Lo que hace es\n",
    "# realizar una segunda cuantización de los pesos ya cuantizados para ahorrar 0.4 bits/parametro.\n",
    "use_nested_quant = True\n",
    "\n",
    "####### Training Arguments param #########\n",
    "\n",
    "#Aqui se guardarán las predicciones y los checkpoints\n",
    "output_dir = \"./resultados\"\n",
    "\n",
    "# Número de epochs (Iteraciones por todo el dataset)\n",
    "num_train_epochs = 1\n",
    "\n",
    "# Enable fp16/bf16 training (set bf16 to True with an A100)\n",
    "fp16 = False\n",
    "bf16 = False\n",
    "\n",
    "# Batch size per GPU for train\n",
    "per_device_train_batch_size = 1\n",
    "\n",
    "# Batch size per GPU for evaluation\n",
    "per_device_eval_batch_size = 2\n",
    "\n",
    "# Number of update steps to accumulate the gradients for\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "gradient_checkpointing = True\n",
    "\n",
    "# Maximum gradient normal (gradient clipping)\n",
    "max_grad_norm = 0.3\n",
    "\n",
    "# Initial learning rate (AdamW optimizer)\n",
    "learning_rate = 2.5e-5\n",
    "\n",
    "# Weight decay to apply to all layers except bias/LayerNorm weights\n",
    "weight_decay = 0.001\n",
    "\n",
    "# Optimizer to use\n",
    "optim = \"paged_adamw_32bit\"\n",
    "\n",
    "# Learning rate schedule (constant a bit better than cosine)\n",
    "lr_scheduler_type = \"constant\"\n",
    "\n",
    "# Number of training steps (overrides num_train_epochs)\n",
    "# The total number of training steps to perform.\n",
    "# Cantidad de batches que pasamos por el modelo\n",
    "# Uso: Inicialmente a muchos steps y comprobamos a partir de que steps el modelo empieza a degradarse. Para evitar hacer muchos entrenamientos\n",
    "# en la proxima iteración empezamos desde un checkpoint.\n",
    "max_steps = 250\n",
    "\n",
    "# Ratio of steps for a linear warmup (from 0 to learning rate)\n",
    "warmup_ratio = 0.03\n",
    "\n",
    "# Group sequences into batches with same length\n",
    "# Saves memory and speeds up training considerably\n",
    "group_by_length = True\n",
    "\n",
    "# Save checkpoint every X updates steps\n",
    "save_steps = 0\n",
    "\n",
    "# Log every X updates steps\n",
    "logging_steps = 1\n",
    "\n",
    "###### Parámetros para SFT ########\n",
    "\n",
    "# Max sequence length\n",
    "max_seq_length = 512\n",
    "\n",
    "# Pack multiple short examples in the same input sequence to increase efficiency\n",
    "packing = False\n",
    "\n",
    "# Load the entire model on the GPU 0\n",
    "# (En el código de Accelerate esta todo explicado)\n",
    "# device_map = {\"\": 0}\n",
    "device_map = \"auto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a51365b6-a74a-403e-a8ef-d73f23ce6366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load base model\n",
    "\n",
    "# Load with QLoRA config\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "# https://huggingface.co/docs/transformers/main_classes/quantization\n",
    "\n",
    "# Con la librería Transformers podemos usar los algoritmos AWQ y GPTQ de cuantización y soporta\n",
    "# cuantizaciones de 4 y 8 bits. (Se pueden añadir más técnicas con la clase HfQuantizer)\n",
    "# En este caso cuantizaremos a 4-bit con el tipo NF4\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b0564fd-8b00-4b9a-a04c-f22b29e008d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|████████████████████████████████████████████████████████████████| 3/3 [03:01<00:00, 60.67s/it]\n",
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 3/3 [00:06<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MistralForCausalLM(\n",
      "  (model): MistralModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x MistralDecoderLayer(\n",
      "        (self_attn): MistralSdpaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): MistralRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): MistralMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): MistralRMSNorm()\n",
      "        (post_attention_layernorm): MistralRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): MistralRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/docs/transformers/model_doc/auto\n",
    "# https://huggingface.co/transformers/v2.9.1/main_classes/model.html\n",
    "\n",
    "# Utilizamos la arquitectura que viene ya incluida en el modelo\n",
    "# Instantiate a pretrained pytorch model from a pre-trained model configuration.\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    low_cpu_mem_usage = True,\n",
    "    device_map = device_map\n",
    ")\n",
    "\n",
    "# https://huggingface.co/transformers/v2.9.1/main_classes/model.html#transformers.PreTrainedModel.generate\n",
    "#Use past key values?\n",
    "base_model.config.use_cache = False  # Nos interesa usar los parametros actualizados, no los viejos (cached)\n",
    "\n",
    "# Mimic the behaviour of the original model at inference?\n",
    "base_model.config.pretraining_tp = 1 #1 = disable\n",
    "\n",
    "print(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23888e13-7c19-4ed7-ba96-2fd2c788be99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "C:\\Users\\201902452\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:688: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the medical treatment for an infection caused by Baylisascaris?\n",
      "\n",
      "Baylisascaris is a parasitic roundworm that can cause infection in humans, particularly through the ingestion of contaminated soil or undercooked pork. The medical treatment for Baylisascaris infection depends on the severity and stage of the infection.\n",
      "\n",
      "For mild to moderate infections, the treatment may involve supportive care, such as:\n",
      "\n",
      "* Anthelmintics (anti-parasitic medications) to kill the parasites, such as albendazole or mebendazole\n",
      "* Symptomatic treatment to manage symptoms, such as antipyretics for fever, antiemetics for nausea and vomiting, and analgesics for pain\n",
      "\n",
      "For severe infections, hospitalization may be necessary for intensive care, including:\n",
      "\n",
      "* Anthelmintics to kill the parasites\n",
      "* Symptomatic treatment to manage symptoms\n",
      "* Nutritional support through intravenous fluids and feeding tubes\n",
      "* Surgical intervention to remove any parasitic lesions or cysts\n",
      "\n",
      "It is important to note that Baylisascaris infection can cause serious neurological damage, and early diagnosis and treatment are crucial for the best possible outcome. Therefore, if you suspect that you have been exposed to Baylisascaris or are experiencing symptoms of infection, seek medical attention promptly.\n"
     ]
    }
   ],
   "source": [
    "# Prueba del modelo base\n",
    "\n",
    "#eval_prompt = \"\"\"Print hello world in python java and c\"\"\"\n",
    "\n",
    "eval_prompt = \"\"\"What is the medical treatment for an infection caused by Baylisascaris?\"\"\"\n",
    "\n",
    "# CUDA: Para programar directamente la GPU\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "base_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(base_model.generate(**model_input, max_new_tokens=512, pad_token_id=2)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1dcf09-2684-40bf-a0ec-55e869ff04d3",
   "metadata": {},
   "source": [
    "## Fine-tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9e034c-452f-4701-9bd7-cb4f6c4b65ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a87f7ab-0d4e-42f7-8940-8f6fbdef119b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7073d1f6-0c96-48a4-9875-9c2592979d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\201902452\\.netrc\n",
      "wandb: Currently logged in as: mrfat. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\201902452\\Downloads\\wandb\\run-20240501_154852-2d1pto6t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mrfat/mistral7b-instruct-medic-v0.2/runs/2d1pto6t' target=\"_blank\">faithful-blaze-3</a></strong> to <a href='https://wandb.ai/mrfat/mistral7b-instruct-medic-v0.2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mrfat/mistral7b-instruct-medic-v0.2' target=\"_blank\">https://wandb.ai/mrfat/mistral7b-instruct-medic-v0.2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mrfat/mistral7b-instruct-medic-v0.2/runs/2d1pto6t' target=\"_blank\">https://wandb.ai/mrfat/mistral7b-instruct-medic-v0.2/runs/2d1pto6t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Log in to WandDB\n",
    "import wandb\n",
    "\n",
    "!wandb login b0ee138ef7cb51349541df5f648e2172d699101c\n",
    "\n",
    "run = wandb.init(\n",
    "    project='mistral7b-instruct-medic-v0.2',\n",
    "    job_type=\"training\",\n",
    "    anonymous=\"allow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c6dafd-dc0b-4a82-b6de-38cfc980d557",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd50477-ee64-4ce0-a605-804556c2cf4d",
   "metadata": {},
   "source": [
    "### MEDIC DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15e50e2c-d53a-4446-a49c-41b60cae478d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|█████████████████████████████████████████████████████████████████| 1.41k/1.41k [00:00<?, ?B/s]\n",
      "Downloading data: 100%|███████████████████████████████████████████████████████████| 10.6M/10.6M [00:01<00:00, 5.63MB/s]\n",
      "Generating train split: 100%|██████████████████████████████████████████| 10000/10000 [00:00<00:00, 75250.89 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'output', 'instruction'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(dataset_name, split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd2f5f6a-8c3b-496b-9436-fc952e386f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATASET MEDIC\n",
    "\n",
    "def formatting_func(example):\n",
    "    text = f\"### The following is a medical question: \\n### Medical question: {example['input']} \\n### Question answer: {example['output']}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "833fe917-86c0-4994-a3a1-7d15c8a57b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbff2750-b7f4-4c6f-9099-3b90646b0907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_tokenize_prompt_test(prompt):\n",
    "    return tokenizer(formatting_func(prompt))\n",
    "\n",
    "def generate_and_tokenize_prompt(prompt):\n",
    "    result = tokenizer(\n",
    "        formatting_func(prompt),\n",
    "        truncation=True,\n",
    "        max_length=max_seq_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6482764-0eaa-466a-a0d8-881cfd8cc0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "train_dataset = dataset['train']\n",
    "eval_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c173e164-b1a4-46e9-af9d-d4fafe69a8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input', 'output', 'instruction'],\n",
      "    num_rows: 8000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "feb109dd-6d99-4bce-9e98-57ec2695d3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input', 'output', 'instruction'],\n",
      "    num_rows: 2000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1adf739-7bba-47e8-b17b-9eb6c004fd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████| 8000/8000 [00:05<00:00, 1573.99 examples/s]\n",
      "Map: 100%|████████████████████████████████████████████████████████████████| 2000/2000 [00:01<00:00, 1573.24 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_train_dataset_test = train_dataset.map(generate_and_tokenize_prompt_test)\n",
    "tokenized_val_dataset_test = eval_dataset.map(generate_and_tokenize_prompt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f302b50-7567-4312-b55a-df72e5db2d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data_lengths(tokenized_train_dataset_test, tokenized_val_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e6f308-8294-41e4-bc29-003fc0812935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2fccf31-c083-404a-a24f-0fe9a44bb1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████| 8000/8000 [00:04<00:00, 1847.43 examples/s]\n",
      "Map: 100%|████████████████████████████████████████████████████████████████| 2000/2000 [00:01<00:00, 1904.27 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "788b60f7-2ee0-49ba-bd03-23cb2cff42b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input', 'output', 'instruction', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 8000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['input', 'output', 'instruction', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 2000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset)\n",
    "print(tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9581d7d8-9c4c-4f70-93bd-e6b682cc8a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7708b2-636f-47ac-82c5-781762961dc6",
   "metadata": {},
   "source": [
    "### LORA CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b3ead0a-3936-4da1-b61e-f5cc1cb923a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): MistralForCausalLM(\n",
      "      (model): MistralModel(\n",
      "        (embed_tokens): Embedding(32000, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x MistralDecoderLayer(\n",
      "            (self_attn): MistralSdpaAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (rotary_emb): MistralRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): MistralMLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=14336, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): MistralRMSNorm()\n",
      "            (post_attention_layernorm): MistralRMSNorm()\n",
      "          )\n",
      "        )\n",
      "        (norm): MistralRMSNorm()\n",
      "      )\n",
      "      (lm_head): lora.Linear(\n",
      "        (base_layer): Linear(in_features=4096, out_features=32000, bias=False)\n",
      "        (lora_dropout): ModuleDict(\n",
      "          (default): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (lora_A): ModuleDict(\n",
      "          (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "        )\n",
      "        (lora_B): ModuleDict(\n",
      "          (default): Linear(in_features=32, out_features=32000, bias=False)\n",
      "        )\n",
      "        (lora_embedding_A): ParameterDict()\n",
      "        (lora_embedding_B): ParameterDict()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Fine-tunning with QLoRA y Supervised Fine Tunning (SFT)\n",
    "from peft import get_peft_model\n",
    "\n",
    "# Set LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# Model with LoRA adapters added\n",
    "print(get_peft_model(base_model, peft_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "633a6c65-16b6-4bf1-acf0-06b9e281ffaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "# Set training parameters (Loading the trainer)\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    fp16=fp16,\n",
    "    bf16=bf16,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=max_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=group_by_length,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    report_to=\"wandb\" #Default logging_dir = *output_dir/runs/CURRENT_DATETIME_HOSTNAME*\n",
    ")\n",
    "\n",
    "# Initialize the SFTTrainer for fine-tuning\n",
    "trainer = SFTTrainer(\n",
    "    model=base_model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,  # Specify the maximum sequence length here\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=packing,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00e5189b-3c72-48bd-a941-16197c7655d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 1:20:20, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.785300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.161900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.981000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.477600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.332500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.546400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.706500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.680400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.640400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.578100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.642800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.655100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.848200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.696100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.769800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.159600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.215600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.680300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.452500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.564100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.295600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.661200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.585800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.701200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.435600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.383800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.104500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.624900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.780500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.310900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.973300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.852300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.661900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.295600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.949200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>2.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.505500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.026700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.259200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.665500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.431900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.258700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.521800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.755300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.388800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.540600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.497400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.481200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.336600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.403300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>2.321000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.114900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.589200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.716200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.337500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.277900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.578900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.258900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>2.462700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>1.997900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>1.548800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>1.175400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.277200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>1.770800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>1.518000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>1.766000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>1.261900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>2.002900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>1.559400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>1.220200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>1.881900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.291600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.755500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>1.463600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>1.475100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.960300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.239200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>1.813900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>1.430200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>1.134200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>1.227900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>1.324200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>2.103900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>1.304800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>1.039000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.918000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>1.471100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>1.118200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.790200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>1.418500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1.504000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>1.215900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>1.428500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.766000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>1.367300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.207500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>1.311900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>1.469700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>1.476300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.949000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>1.304500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>1.773000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.709500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>1.314700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>1.945500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.610900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.671700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>1.944900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>1.735200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>1.378900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>2.288500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.822100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>1.885400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>1.952100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>1.589500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.029300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>1.468300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>1.473200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>1.933100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>1.709100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.251800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>1.097600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>1.118400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>1.332400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>1.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.431000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>0.803900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>1.072200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>1.283000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>1.525500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>1.719600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>1.154300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>1.700700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>2.049100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>0.903000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.104100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>1.203800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>1.581100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>1.419000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>1.515600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>2.464800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>1.954700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>1.288100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>1.170200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>0.821500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.225200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>1.946500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>1.815500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>1.536200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>1.471100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.673400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>1.299200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>1.023300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>1.073700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>1.129000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.723200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>1.675500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>1.214900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>1.404500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>2.273400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>1.466900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>1.263200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>1.363800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>0.650300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>1.662000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.859300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>1.280700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>2.581800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>1.461600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>1.065800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.538300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>1.195700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>1.757300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>2.089500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>1.803800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.915800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>1.664300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>1.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>1.063600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>1.652500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>1.371000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>1.192300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>1.790100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>1.671000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>1.151300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.863100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>2.130100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>1.443100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>1.036300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>2.112300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>1.435200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>1.961600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>1.040800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>1.291900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>1.415100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.609500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201</td>\n",
       "      <td>1.127200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>1.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>1.276700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>1.243900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>1.318600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>1.299600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>1.089800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>1.184400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209</td>\n",
       "      <td>2.049300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.308900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211</td>\n",
       "      <td>1.425200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212</td>\n",
       "      <td>1.956700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213</td>\n",
       "      <td>2.153500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214</td>\n",
       "      <td>1.364000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>1.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>1.857600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>1.193100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>1.541000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219</td>\n",
       "      <td>1.097600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.245500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221</td>\n",
       "      <td>1.451300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222</td>\n",
       "      <td>1.219600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223</td>\n",
       "      <td>1.414100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>1.803300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>1.162000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>1.234300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227</td>\n",
       "      <td>0.951600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>1.718100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>229</td>\n",
       "      <td>1.718500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.660500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231</td>\n",
       "      <td>1.988900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232</td>\n",
       "      <td>0.988700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233</td>\n",
       "      <td>1.365400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234</td>\n",
       "      <td>1.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>1.039300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>1.787200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>1.724000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>1.670100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239</td>\n",
       "      <td>0.739000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.571400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>241</td>\n",
       "      <td>0.818600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>0.821100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>243</td>\n",
       "      <td>1.666800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>0.767100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>1.520200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>1.105700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>0.995100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>1.459400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>1.757400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.909800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\201902452\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\peft\\utils\\save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>█▄▃▂▁▁▃▂▄▄▃▂▁▄▂▄▂▂▃▁▂▂▃▂▂▁▃▄▁▂▁▁▁▄▃▂▁▄▃▂</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>▆▆▅▄▃▂▂▅▃▃▂▅▄▃▁▃▄▄▁▄▃▄▂▂▄▅▃█▅▂▃▃▃▃▄▅▄▅▁▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>5526298558464000.0</td></tr><tr><td>train/epoch</td><td>0.03125</td></tr><tr><td>train/global_step</td><td>250</td></tr><tr><td>train/grad_norm</td><td>7.3682</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/loss</td><td>1.9098</td></tr><tr><td>train_loss</td><td>1.48015</td></tr><tr><td>train_runtime</td><td>4841.7078</td></tr><tr><td>train_samples_per_second</td><td>0.052</td></tr><tr><td>train_steps_per_second</td><td>0.052</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">faithful-blaze-3</strong> at: <a href='https://wandb.ai/mrfat/mistral7b-instruct-medic-v0.2/runs/2d1pto6t' target=\"_blank\">https://wandb.ai/mrfat/mistral7b-instruct-medic-v0.2/runs/2d1pto6t</a><br/> View project at: <a href='https://wandb.ai/mrfat/mistral7b-instruct-medic-v0.2' target=\"_blank\">https://wandb.ai/mrfat/mistral7b-instruct-medic-v0.2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240501_154852-2d1pto6t\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5416345600\n"
     ]
    }
   ],
   "source": [
    "###### START TRAIN ########\n",
    "\n",
    "# Initialize SFTTrainer (Wandb starts automatically when this is run)\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model (\"Insertar path aqui\")\n",
    "trainer.model.save_pretrained(fine_tuned_model)\n",
    "tokenizer.save_pretrained(fine_tuned_model)\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "# www.wandb.ai/<your-profile-name>/projects\n",
    "\n",
    "base_model.config.use_cache = True\n",
    "base_model.eval()\n",
    "\n",
    "print(base_model.get_memory_footprint())\n",
    "\n",
    "###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4a3b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como el train y el validation se van reduciendo, podemos afirmar que el modelo esta entrenando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd53036-68ed-4353-8665-c5da1b0031c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4945af8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] What is the medical treatment for an infection caused by Baylisascaris? [/INST] There is no specific medical treatment for Baylisascaris infection. The treatment is supportive and includes:\n",
      "\n",
      "1. Antiparasitic drugs: Antiparasitic drugs such as albendazole or mebendazole may be used to treat the infection. However, the effectiveness of these drugs is not well established.\n",
      "2. Symptomatic treatment: Symptomatic treatment may include:\n",
      "   a. Anticonvulsants: To control seizures.\n",
      "   b. Corticosteroids: To reduce inflammation and swelling.\n",
      "   c. Antitussives: To control coughing.\n",
      "   d. Antiemetics: To control vomiting.\n",
      "   e. Antipsychotics: To control behavioral disturbances.\n",
      "   f. Antibiotics:\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is the medical treatment for an infection caused by Baylisascaris?\"\n",
    "pipe = pipeline(task=\"text-generation\", model=base_model, tokenizer=tokenizer, max_length=200)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9adc27-1081-4d5a-972b-7be72d4171c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033aafba-89c0-4696-8264-a4676e8aee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty VRAM\n",
    "del base_model, trainer\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cfe659-1ae0-4df3-9af8-efd427f8b567",
   "metadata": {},
   "source": [
    "#### Model merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e8be805-9b9b-4a88-8f55-cd89f40c8935",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  6.17it/s]\n",
      "C:\\Users\\201902452\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\utils\\modeling.py:1363: UserWarning: Current model requires 536879104 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Reload the base model\n",
    "base_model_reload = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id, \n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map= device_map)\n",
    "\n",
    "# load the base model with the PEFT configuration from \"fine_tuned_model\" directory\n",
    "model = PeftModel.from_pretrained(base_model_reload, fine_tuned_model)\n",
    "\n",
    "# Reload tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38c7615-dcc2-43b1-a062-e0854a8013ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "119a4693-ce41-40d1-aa6c-080e2485ad92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model-00001-of-00003.safetensors:   0%|                                                    | 0.00/4.94G [00:00<?, ?B/s]\n",
      "Upload 3 LFS files:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   0%|                                                    | 0.00/5.00G [00:00<?, ?B/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   0%|                                                    | 0.00/4.54G [00:00<?, ?B/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   0%|                                        | 16.4k/4.94G [00:00<58:11:28, 23.6kB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   0%|                                           | 8.21M/5.00G [00:00<05:21, 15.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   0%|                                           | 1.64M/4.94G [00:00<30:36, 2.69MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   0%|                                           | 5.44M/4.54G [00:00<09:01, 8.37MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   0%|                                           | 2.44M/4.94G [00:01<28:20, 2.91MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   0%|                                           | 6.98M/4.94G [00:01<08:18, 9.91MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   0%|▏                                          | 15.2M/4.94G [00:01<03:10, 25.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   1%|▎                                          | 28.2M/4.54G [00:01<02:33, 29.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   0%|▏                                          | 17.3M/5.00G [00:01<08:02, 10.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   0%|▏                                          | 22.2M/5.00G [00:01<05:31, 15.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   1%|▏                                          | 25.9M/5.00G [00:01<05:24, 15.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   1%|▏                                          | 27.5M/4.94G [00:02<04:52, 16.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   1%|▎                                          | 31.2M/4.94G [00:02<04:10, 19.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   1%|▎                                          | 32.0M/5.00G [00:02<07:12, 11.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   1%|▍                                          | 42.7M/4.54G [00:02<03:51, 19.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   1%|▍                                          | 43.5M/4.94G [00:02<02:57, 27.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   1%|▎                                          | 42.0M/5.00G [00:03<05:17, 15.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   1%|▍                                          | 47.5M/4.54G [00:03<04:38, 16.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   1%|▍                                          | 51.6M/4.94G [00:03<04:03, 20.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   1%|▍                                          | 51.2M/4.54G [00:03<05:31, 13.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   1%|▍                                          | 48.0M/5.00G [00:03<06:33, 12.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   1%|▌                                          | 58.8M/4.54G [00:03<04:02, 18.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   1%|▌                                          | 58.1M/4.94G [00:03<03:51, 21.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   1%|▍                                          | 57.2M/5.00G [00:03<04:03, 20.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   1%|▌                                          | 64.0M/4.94G [00:04<04:17, 19.0MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   1%|▌                                          | 66.4M/4.94G [00:04<04:10, 19.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   1%|▌                                          | 68.8M/4.94G [00:04<04:59, 16.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   1%|▌                                          | 70.8M/4.94G [00:04<05:17, 15.3MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   2%|▋                                          | 74.8M/4.54G [00:04<03:48, 19.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   1%|▋                                          | 72.5M/4.94G [00:04<05:09, 15.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   2%|▋                                          | 75.2M/4.94G [00:04<04:30, 18.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   1%|▋                                          | 73.3M/5.00G [00:04<04:33, 18.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   2%|▋                                          | 80.0M/4.94G [00:05<05:56, 13.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   2%|▋                                          | 75.8M/5.00G [00:05<06:24, 12.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   2%|▋                                          | 84.4M/4.94G [00:05<05:26, 14.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   2%|▋                                          | 86.2M/4.94G [00:05<06:09, 13.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   2%|▊                                          | 87.9M/4.94G [00:05<05:58, 13.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   2%|▊                                          | 94.8M/4.94G [00:06<03:39, 22.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   2%|▋                                          | 86.3M/5.00G [00:06<06:03, 13.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   2%|▉                                          | 95.0M/4.54G [00:06<05:02, 14.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   2%|▊                                          | 97.4M/4.94G [00:06<05:31, 14.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   2%|▊                                          | 99.4M/4.94G [00:06<05:32, 14.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   2%|▉                                           | 103M/4.94G [00:06<04:33, 17.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   2%|▉                                           | 107M/4.94G [00:06<03:45, 21.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   2%|▉                                           | 110M/4.94G [00:06<03:40, 21.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   2%|▉                                           | 112M/4.94G [00:07<04:46, 16.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   3%|█                                           | 115M/4.54G [00:07<03:38, 20.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   2%|█                                           | 115M/4.94G [00:07<04:07, 19.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   3%|█▏                                          | 122M/4.54G [00:07<02:51, 25.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   3%|█                                           | 126M/4.94G [00:07<02:16, 35.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   3%|█▎                                          | 141M/4.94G [00:07<01:55, 41.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   3%|█▎                                          | 147M/4.94G [00:08<02:42, 29.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   3%|█▎                                          | 151M/4.94G [00:08<02:41, 29.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   3%|█▍                                          | 160M/4.94G [00:08<02:36, 30.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   4%|█▌                                          | 174M/4.94G [00:08<01:45, 45.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   3%|█▎                                          | 147M/5.00G [00:08<02:29, 32.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   3%|█▍                                          | 158M/5.00G [00:09<01:48, 44.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   3%|█▏                                          | 128M/4.54G [00:09<08:59, 8.19MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   3%|█▍                                          | 164M/5.00G [00:09<02:32, 31.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   4%|█▌                                          | 180M/4.94G [00:09<03:42, 21.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   4%|█▋                                          | 184M/4.94G [00:09<03:39, 21.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   3%|█▍                                          | 147M/4.54G [00:09<04:46, 15.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   3%|█▍                                          | 154M/4.54G [00:09<03:38, 20.0MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   4%|█▋                                          | 191M/4.94G [00:10<03:38, 21.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   4%|█▌                                          | 160M/4.54G [00:10<03:50, 19.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   4%|█▋                                          | 194M/4.94G [00:10<04:23, 18.0MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   4%|█▋                                          | 196M/4.94G [00:10<04:05, 19.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   4%|█▊                                          | 200M/4.94G [00:10<03:35, 22.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   4%|█▋                                          | 191M/5.00G [00:10<02:37, 30.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   4%|█▊                                          | 204M/4.94G [00:10<03:10, 24.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   4%|█▊                                          | 210M/4.94G [00:11<04:07, 19.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   4%|█▉                                          | 215M/4.94G [00:11<03:21, 23.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   4%|█▊                                          | 202M/5.00G [00:11<03:00, 26.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   4%|█▉                                          | 219M/4.94G [00:11<02:56, 26.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   4%|█▉                                          | 222M/4.94G [00:11<02:48, 28.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   5%|██                                          | 207M/4.54G [00:11<02:03, 35.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   4%|█▊                                          | 208M/5.00G [00:11<03:30, 22.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   5%|██                                          | 225M/4.94G [00:11<03:41, 21.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   5%|██                                          | 229M/4.94G [00:11<03:21, 23.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   5%|██                                          | 233M/4.94G [00:11<02:49, 27.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   5%|██                                          | 237M/4.94G [00:11<02:36, 30.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   5%|██                                          | 231M/5.00G [00:11<02:19, 34.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   5%|██▏                                         | 240M/4.94G [00:12<03:34, 22.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   5%|██▏                                         | 248M/4.94G [00:12<02:25, 32.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   5%|██                                          | 240M/5.00G [00:12<02:33, 30.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   5%|██▏                                         | 252M/4.94G [00:12<02:21, 33.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   5%|██▏                                         | 246M/5.00G [00:12<02:17, 34.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   5%|██▎                                         | 256M/4.94G [00:12<02:21, 33.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   5%|██▎                                         | 244M/4.54G [00:12<02:22, 30.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   5%|██▍                                         | 269M/4.94G [00:12<02:08, 36.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   5%|██▎                                         | 256M/5.00G [00:12<03:09, 25.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   5%|██▎                                         | 267M/5.00G [00:13<02:04, 38.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   6%|██▍                                         | 273M/4.94G [00:13<02:50, 27.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   6%|██▌                                         | 288M/4.94G [00:13<02:36, 29.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   6%|██▌                                         | 293M/4.94G [00:13<02:23, 32.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   6%|██▋                                         | 283M/4.54G [00:13<02:16, 31.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   6%|██▋                                         | 297M/4.94G [00:13<02:13, 34.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   6%|██▊                                         | 288M/4.54G [00:13<02:05, 33.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   6%|██▋                                         | 301M/4.94G [00:13<02:09, 35.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   6%|██▍                                         | 281M/5.00G [00:13<03:22, 23.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   6%|██▋                                         | 306M/4.94G [00:14<03:06, 24.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   7%|██▉                                         | 299M/4.54G [00:14<02:14, 31.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   6%|██▊                                         | 311M/4.94G [00:14<02:37, 29.3MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   7%|██▉                                         | 304M/4.54G [00:14<02:03, 34.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   6%|██▊                                         | 315M/4.94G [00:14<02:31, 30.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   6%|██▌                                         | 297M/5.00G [00:14<02:46, 28.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   7%|██▉                                         | 330M/4.94G [00:14<01:58, 38.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   6%|██▋                                         | 304M/5.00G [00:14<03:36, 21.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   7%|███                                         | 312M/4.54G [00:15<03:38, 19.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   6%|██▊                                         | 315M/5.00G [00:15<02:17, 34.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   7%|██▉                                         | 336M/4.94G [00:15<02:57, 26.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   6%|██▊                                         | 321M/5.00G [00:15<02:34, 30.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   7%|███                                         | 343M/4.94G [00:15<02:23, 32.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   7%|███                                         | 348M/4.94G [00:15<02:17, 33.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   7%|███▏                                        | 352M/4.94G [00:15<02:41, 28.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   7%|███▏                                        | 362M/4.94G [00:15<01:52, 40.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   7%|███                                         | 320M/4.54G [00:15<05:52, 12.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   7%|███                                         | 342M/5.00G [00:15<02:13, 34.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   7%|███▎                                        | 367M/4.94G [00:15<01:50, 41.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   7%|███                                         | 347M/5.00G [00:16<02:09, 36.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   7%|███▏                                        | 332M/4.54G [00:16<03:02, 23.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   7%|███▎                                        | 336M/4.54G [00:16<03:55, 17.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   8%|███▍                                        | 349M/4.54G [00:16<02:02, 34.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   7%|███                                         | 352M/5.00G [00:16<03:57, 19.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   8%|███▍                                        | 383M/4.94G [00:16<02:53, 26.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   7%|███▎                                        | 370M/5.00G [00:16<02:32, 30.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   8%|███▌                                        | 400M/4.94G [00:17<02:07, 35.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   8%|███▍                                        | 388M/5.00G [00:17<02:08, 35.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   8%|███▌                                        | 399M/5.00G [00:17<01:36, 47.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   8%|███▍                                        | 355M/4.54G [00:17<04:30, 15.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   8%|███▌                                        | 367M/4.54G [00:17<02:44, 25.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   8%|███▌                                        | 406M/4.94G [00:17<03:01, 25.0MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   8%|███▋                                        | 411M/4.94G [00:17<02:42, 27.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   8%|███▌                                        | 374M/4.54G [00:17<02:52, 24.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   8%|███▋                                        | 380M/4.54G [00:17<02:27, 28.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   8%|███▋                                        | 418M/5.00G [00:18<02:16, 33.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   9%|███▊                                        | 423M/4.94G [00:18<02:34, 29.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   9%|███▊                                        | 428M/4.94G [00:18<02:15, 33.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   9%|███▊                                        | 394M/4.54G [00:18<02:03, 33.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   9%|███▊                                        | 435M/5.00G [00:18<02:07, 35.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   9%|███▊                                        | 400M/4.54G [00:18<01:51, 37.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   9%|███▊                                        | 433M/4.94G [00:18<02:58, 25.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   9%|███▉                                        | 441M/4.94G [00:18<02:13, 33.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   9%|███▉                                        | 446M/4.94G [00:18<02:03, 36.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   9%|███▉                                        | 448M/5.00G [00:18<02:29, 30.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   9%|███▉                                        | 454M/5.00G [00:19<02:08, 35.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   9%|████                                        | 451M/4.94G [00:19<02:31, 29.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   9%|████                                        | 461M/4.94G [00:19<01:44, 42.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   9%|████▏                                       | 426M/4.54G [00:19<01:54, 35.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:   9%|████▏                                       | 470M/5.00G [00:19<02:08, 35.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:   9%|████▏                                       | 467M/4.94G [00:19<02:18, 32.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  10%|████▏                                       | 474M/4.94G [00:19<01:59, 37.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  10%|████▏                                       | 432M/4.54G [00:19<02:38, 26.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  10%|████▎                                       | 485M/5.00G [00:19<02:20, 32.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  10%|████▎                                       | 443M/4.54G [00:19<01:50, 37.0MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  10%|████▎                                       | 480M/4.94G [00:20<02:31, 29.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  10%|████▎                                       | 485M/4.94G [00:20<02:15, 32.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  10%|████▎                                       | 449M/4.54G [00:20<02:24, 28.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  10%|████▍                                       | 500M/5.00G [00:20<02:33, 29.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  10%|████▍                                       | 460M/4.54G [00:20<01:43, 39.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  10%|████▍                                       | 496M/4.94G [00:20<02:24, 30.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  10%|████▍                                       | 502M/4.94G [00:20<02:03, 35.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  10%|████▌                                       | 466M/4.54G [00:20<02:18, 29.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  10%|████▌                                       | 512M/4.94G [00:20<02:08, 34.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  11%|████▋                                       | 521M/4.94G [00:21<01:45, 41.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  11%|████▋                                       | 527M/4.94G [00:21<01:39, 44.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  11%|████▌                                       | 525M/5.00G [00:21<02:31, 29.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  11%|████▋                                       | 487M/4.54G [00:21<01:57, 34.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  11%|████▊                                       | 493M/4.54G [00:21<01:46, 38.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  11%|████▋                                       | 532M/4.94G [00:21<02:15, 32.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  11%|████▊                                       | 537M/4.94G [00:21<02:03, 35.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  11%|████▊                                       | 498M/4.54G [00:21<02:10, 31.0MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  11%|████▊                                       | 542M/4.94G [00:21<01:57, 37.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  11%|████▉                                       | 504M/4.54G [00:21<01:57, 34.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  11%|████▊                                       | 546M/4.94G [00:21<02:29, 29.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  11%|████▉                                       | 553M/4.94G [00:22<02:03, 35.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  11%|████▉                                       | 558M/4.94G [00:22<01:50, 39.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  11%|████▉                                       | 515M/4.54G [00:22<02:17, 29.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  11%|████▉                                       | 556M/5.00G [00:22<02:08, 34.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  11%|█████                                       | 563M/4.94G [00:22<02:27, 29.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  12%|█████                                       | 573M/4.94G [00:22<01:41, 43.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  11%|█████                                       | 568M/5.00G [00:22<02:05, 35.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  12%|█████                                       | 528M/4.54G [00:22<02:29, 26.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  12%|█████                                       | 575M/5.00G [00:22<01:43, 42.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  12%|█████▏                                      | 588M/4.94G [00:22<01:45, 41.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  12%|█████                                       | 581M/5.00G [00:22<02:22, 31.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  12%|█████▎                                      | 544M/4.54G [00:23<02:22, 28.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  12%|█████▏                                      | 591M/5.00G [00:23<01:42, 43.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  12%|█████▎                                      | 599M/4.94G [00:23<01:58, 36.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  12%|█████▍                                      | 606M/4.94G [00:23<01:43, 41.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  12%|█████▎                                      | 605M/5.00G [00:23<01:48, 40.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  12%|█████▍                                      | 562M/4.54G [00:23<02:10, 30.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  12%|█████▍                                      | 617M/4.94G [00:23<01:57, 36.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  13%|█████▌                                      | 623M/4.94G [00:23<01:43, 41.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  12%|█████▍                                      | 617M/5.00G [00:23<02:02, 35.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  13%|█████▌                                      | 579M/4.54G [00:23<02:08, 30.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  13%|█████▌                                      | 628M/4.94G [00:24<02:19, 30.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  13%|█████▋                                      | 633M/4.94G [00:24<02:01, 35.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  13%|█████▋                                      | 639M/4.94G [00:24<01:49, 39.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  13%|█████▊                                      | 597M/4.54G [00:24<01:48, 36.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  13%|█████▌                                      | 637M/5.00G [00:24<01:50, 39.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  13%|█████▋                                      | 644M/4.94G [00:24<02:43, 26.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  13%|█████▊                                      | 652M/4.94G [00:24<02:01, 35.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  13%|█████▋                                      | 647M/5.00G [00:24<02:11, 33.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  13%|█████▉                                      | 608M/4.54G [00:24<02:16, 28.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  13%|█████▋                                      | 651M/5.00G [00:24<02:04, 34.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  14%|█████▉                                      | 616M/4.54G [00:24<01:45, 37.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  14%|█████▉                                      | 672M/4.94G [00:25<01:32, 46.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  13%|█████▊                                      | 656M/5.00G [00:25<03:06, 23.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  14%|██████                                      | 678M/4.94G [00:25<02:11, 32.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  14%|██████                                      | 627M/4.54G [00:25<03:06, 21.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  13%|█████▉                                      | 675M/5.00G [00:25<02:20, 30.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  14%|██████▏                                     | 635M/4.54G [00:25<02:20, 27.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  14%|█████▉                                      | 680M/5.00G [00:25<02:03, 34.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  14%|██████▏                                     | 695M/4.94G [00:26<02:00, 35.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  14%|██████▎                                     | 704M/4.94G [00:26<01:33, 45.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  14%|██████▎                                     | 652M/4.54G [00:26<01:49, 35.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  14%|██████                                      | 691M/5.00G [00:26<02:43, 26.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  14%|██████▎                                     | 710M/4.94G [00:26<01:58, 35.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  14%|██████▏                                     | 702M/5.00G [00:26<02:03, 34.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  14%|██████▍                                     | 717M/4.94G [00:26<01:44, 40.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  15%|██████▍                                     | 722M/4.94G [00:26<02:09, 32.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  15%|██████▍                                     | 729M/4.94G [00:26<01:46, 39.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  15%|██████▌                                     | 735M/4.94G [00:27<01:37, 43.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  14%|██████▎                                     | 719M/5.00G [00:27<01:54, 37.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  15%|██████▌                                     | 672M/4.54G [00:27<02:30, 25.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  15%|██████▌                                     | 741M/4.94G [00:27<02:08, 32.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  15%|██████▋                                     | 747M/4.94G [00:27<01:50, 37.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  15%|██████▍                                     | 729M/5.00G [00:27<02:10, 32.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  15%|██████▋                                     | 692M/4.54G [00:27<01:56, 33.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  15%|██████▍                                     | 735M/5.00G [00:27<01:52, 37.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  15%|██████▊                                     | 761M/4.94G [00:27<01:46, 39.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  16%|██████▊                                     | 767M/4.94G [00:27<01:37, 42.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  15%|██████▌                                     | 745M/5.00G [00:27<02:06, 33.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  16%|██████▊                                     | 705M/4.54G [00:27<02:09, 29.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  15%|██████▌                                     | 751M/5.00G [00:27<01:47, 39.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  16%|██████▉                                     | 783M/4.94G [00:28<01:31, 45.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  15%|██████▋                                     | 756M/5.00G [00:28<02:45, 25.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  16%|██████▉                                     | 720M/4.54G [00:28<02:05, 30.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  15%|██████▋                                     | 762M/5.00G [00:28<02:08, 33.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  16%|███████                                     | 729M/4.54G [00:28<01:37, 39.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  15%|██████▊                                     | 767M/5.00G [00:28<01:58, 35.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  16%|███████                                     | 794M/4.94G [00:28<02:03, 33.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  15%|██████▊                                     | 772M/5.00G [00:28<02:35, 27.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  16%|███████▏                                    | 740M/4.54G [00:28<02:05, 30.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  16%|██████▊                                     | 781M/5.00G [00:28<01:52, 37.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  16%|███████▏                                    | 806M/4.94G [00:29<02:05, 32.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  16%|███████▏                                    | 814M/4.94G [00:29<01:39, 41.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  16%|██████▉                                     | 792M/5.00G [00:29<01:57, 35.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  17%|███████▎                                    | 752M/4.54G [00:29<02:24, 26.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  17%|███████▎                                    | 828M/4.94G [00:29<01:40, 40.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  16%|███████                                     | 800M/5.00G [00:29<02:24, 29.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  16%|███████▏                                    | 810M/5.00G [00:29<01:43, 40.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  17%|███████▍                                    | 770M/4.54G [00:29<02:14, 28.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  17%|███████▌                                    | 783M/4.54G [00:30<01:29, 41.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  17%|███████▍                                    | 834M/4.94G [00:30<02:29, 27.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  17%|███████▍                                    | 839M/4.94G [00:30<02:16, 30.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  17%|███████▌                                    | 845M/4.94G [00:30<01:58, 34.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  17%|███████▋                                    | 790M/4.54G [00:30<01:52, 33.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  18%|███████▋                                    | 798M/4.54G [00:30<01:32, 40.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  17%|███████▌                                    | 850M/4.94G [00:30<02:37, 26.0MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  17%|███████▌                                    | 855M/4.94G [00:30<02:14, 30.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  17%|███████▍                                    | 846M/5.00G [00:30<01:43, 40.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  17%|███████▋                                    | 860M/4.94G [00:30<02:03, 33.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  17%|███████▋                                    | 864M/4.94G [00:31<02:40, 25.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  18%|███████▉                                    | 816M/4.54G [00:31<01:59, 31.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  18%|███████▋                                    | 870M/4.94G [00:31<02:14, 30.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  18%|███████▉                                    | 824M/4.54G [00:31<01:36, 38.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  18%|███████▊                                    | 874M/4.94G [00:31<02:08, 31.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  18%|████████                                    | 829M/4.54G [00:31<01:36, 38.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  18%|███████▊                                    | 878M/4.94G [00:31<02:03, 32.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  17%|███████▌                                    | 862M/5.00G [00:31<02:18, 29.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  18%|███████▊                                    | 881M/4.94G [00:31<02:56, 23.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  17%|███████▌                                    | 866M/5.00G [00:31<02:58, 23.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  18%|███████▉                                    | 886M/4.94G [00:31<02:28, 27.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  17%|███████▋                                    | 870M/5.00G [00:31<02:43, 25.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  18%|███████▉                                    | 890M/4.94G [00:31<02:19, 29.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  18%|███████▉                                    | 893M/4.94G [00:32<02:12, 30.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  18%|███████▋                                    | 877M/5.00G [00:32<02:20, 29.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  18%|███████▋                                    | 881M/5.00G [00:32<02:42, 25.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  18%|███████▉                                    | 897M/4.94G [00:32<03:01, 22.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  18%|███████▊                                    | 887M/5.00G [00:32<02:02, 33.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  18%|████████                                    | 901M/4.94G [00:32<02:39, 25.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  18%|███████▊                                    | 891M/5.00G [00:32<01:58, 34.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  18%|████████                                    | 905M/4.94G [00:32<02:26, 27.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  18%|████████                                    | 909M/4.94G [00:32<02:14, 29.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  18%|████████                                    | 912M/4.94G [00:32<03:03, 21.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  19%|████████▏                                   | 926M/4.94G [00:33<01:40, 40.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  19%|████████▎                                   | 936M/4.94G [00:33<02:02, 32.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  20%|████████▌                                   | 890M/4.54G [00:33<02:00, 30.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  19%|████████▌                                   | 957M/4.94G [00:34<01:39, 40.3MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  20%|████████▋                                   | 900M/4.54G [00:34<03:00, 20.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  19%|████████▌                                   | 963M/4.94G [00:34<02:05, 31.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  20%|████████▋                                   | 970M/4.94G [00:34<01:42, 38.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  20%|████████▊                                   | 989M/4.94G [00:34<01:24, 46.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  20%|████████▉                                   | 917M/4.54G [00:34<02:58, 20.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  18%|████████                                    | 912M/5.00G [00:34<05:38, 12.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  20%|████████▉                                   | 926M/4.54G [00:34<02:08, 28.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  20%|████████▊                                   | 995M/4.94G [00:35<01:50, 35.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  20%|████████▋                                  | 1.00G/4.94G [00:35<01:39, 39.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  19%|████████▏                                   | 931M/5.00G [00:35<03:17, 20.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  20%|████████▊                                  | 1.01G/4.94G [00:35<02:15, 29.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  21%|████████▊                                  | 1.02G/4.94G [00:35<01:44, 37.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  21%|████████▉                                  | 1.02G/4.94G [00:35<01:35, 40.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  19%|████████▎                                   | 948M/5.00G [00:35<02:23, 28.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  21%|█████████▏                                  | 943M/4.54G [00:35<02:29, 24.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  21%|████████▉                                  | 1.03G/4.94G [00:36<01:58, 33.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  21%|█████████                                  | 1.04G/4.94G [00:36<01:32, 42.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  21%|█████████▏                                 | 1.05G/4.94G [00:36<01:23, 46.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  21%|█████████▎                                  | 960M/4.54G [00:36<02:30, 23.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  19%|████████▍                                   | 960M/5.00G [00:36<03:48, 17.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  21%|█████████▍                                  | 975M/4.54G [00:36<01:26, 41.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  21%|█████████▏                                 | 1.06G/4.94G [00:36<01:51, 34.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  22%|█████████▎                                 | 1.06G/4.94G [00:36<01:42, 37.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  22%|█████████▎                                 | 1.07G/4.94G [00:37<01:25, 45.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  22%|█████████▌                                  | 990M/4.54G [00:37<01:25, 41.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  20%|████████▌                                   | 978M/5.00G [00:37<02:53, 23.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  22%|█████████▍                                 | 1.09G/4.94G [00:37<01:33, 41.3MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  22%|█████████▋                                  | 997M/4.54G [00:37<01:51, 31.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  20%|████████▋                                   | 993M/5.00G [00:37<02:17, 29.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  22%|█████████▌                                 | 1.01G/4.54G [00:37<01:29, 39.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  20%|████████▌                                  | 1.00G/5.00G [00:37<01:53, 35.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  22%|█████████▌                                 | 1.10G/4.94G [00:37<01:41, 37.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  22%|█████████▌                                 | 1.01G/4.54G [00:37<01:54, 30.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  22%|█████████▋                                 | 1.02G/4.54G [00:38<01:32, 38.0MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  22%|█████████▌                                 | 1.10G/4.94G [00:38<02:11, 29.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  22%|█████████▋                                 | 1.11G/4.94G [00:38<01:51, 34.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  23%|█████████▋                                 | 1.02G/4.54G [00:38<02:10, 27.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  23%|█████████▊                                 | 1.04G/4.54G [00:38<01:21, 43.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  21%|████████▊                                  | 1.03G/5.00G [00:38<02:05, 31.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  23%|█████████▊                                 | 1.13G/4.94G [00:38<01:48, 35.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  23%|█████████▊                                 | 1.13G/4.94G [00:38<01:31, 41.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  23%|█████████▉                                 | 1.05G/4.54G [00:38<01:30, 38.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  21%|████████▉                                  | 1.04G/5.00G [00:38<02:09, 30.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  21%|█████████                                  | 1.05G/5.00G [00:39<01:41, 38.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  23%|█████████▉                                 | 1.14G/4.94G [00:39<02:01, 31.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  23%|█████████▉                                 | 1.15G/4.94G [00:39<01:29, 42.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  23%|██████████                                 | 1.07G/4.54G [00:39<01:29, 38.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  21%|█████████▏                                 | 1.06G/5.00G [00:39<02:02, 32.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  21%|█████████▏                                 | 1.07G/5.00G [00:39<01:32, 42.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  24%|██████████▏                                | 1.07G/4.54G [00:39<01:50, 31.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  24%|██████████                                 | 1.16G/4.94G [00:40<02:03, 30.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  22%|█████████▎                                 | 1.08G/5.00G [00:40<02:31, 25.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  24%|██████████▎                                | 1.09G/4.54G [00:40<01:37, 35.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  22%|█████████▎                                 | 1.08G/5.00G [00:40<02:14, 29.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  24%|██████████▏                                | 1.18G/4.94G [00:40<01:54, 32.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  22%|█████████▎                                 | 1.09G/5.00G [00:40<02:39, 24.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  24%|██████████▍                                | 1.11G/4.54G [00:40<01:54, 30.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  22%|█████████▍                                 | 1.10G/5.00G [00:40<01:46, 36.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  24%|██████████▎                                | 1.18G/4.94G [00:40<02:21, 26.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  24%|██████████▍                                | 1.19G/4.94G [00:40<01:40, 37.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  22%|█████████▌                                 | 1.11G/5.00G [00:41<01:52, 34.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  25%|██████████▌                                | 1.12G/4.54G [00:41<01:57, 29.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  22%|█████████▌                                 | 1.12G/5.00G [00:41<01:43, 37.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  24%|██████████▍                                | 1.20G/4.94G [00:41<01:53, 33.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  24%|██████████▍                                | 1.21G/4.94G [00:41<01:47, 34.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  22%|█████████▋                                 | 1.12G/5.00G [00:41<02:17, 28.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  23%|█████████▋                                 | 1.13G/5.00G [00:41<01:35, 40.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  25%|██████████▊                                | 1.14G/4.54G [00:41<01:48, 31.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  25%|██████████▋                                | 1.22G/4.94G [00:41<01:45, 35.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  25%|██████████▋                                | 1.23G/4.94G [00:41<01:26, 42.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  23%|█████████▊                                 | 1.14G/5.00G [00:41<01:47, 35.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  25%|██████████▉                                | 1.15G/4.54G [00:42<02:14, 25.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  25%|██████████▊                                | 1.24G/4.94G [00:42<01:33, 39.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  23%|█████████▉                                 | 1.15G/5.00G [00:42<02:13, 28.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  23%|██████████                                 | 1.16G/5.00G [00:42<01:31, 41.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  26%|███████████                                | 1.17G/4.54G [00:42<01:41, 33.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  25%|██████████▉                                | 1.25G/4.94G [00:42<01:44, 35.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  26%|██████████▉                                | 1.26G/4.94G [00:42<01:30, 40.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  24%|██████████                                 | 1.18G/5.00G [00:42<01:41, 37.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  26%|███████████▎                               | 1.19G/4.54G [00:42<01:36, 34.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  24%|██████████▏                                | 1.18G/5.00G [00:42<01:34, 40.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  26%|███████████                                | 1.28G/4.94G [00:43<01:27, 42.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  24%|██████████▏                                | 1.19G/5.00G [00:43<02:06, 30.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  24%|██████████▎                                | 1.20G/5.00G [00:43<01:31, 41.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  26%|███████████▎                               | 1.20G/4.54G [00:43<02:04, 26.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  26%|███████████▏                               | 1.29G/4.94G [00:43<01:38, 36.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  26%|███████████▎                               | 1.29G/4.94G [00:43<01:29, 41.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  24%|██████████▍                                | 1.21G/5.00G [00:43<01:43, 36.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  27%|███████████▌                               | 1.22G/4.54G [00:43<01:45, 31.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  24%|██████████▍                                | 1.22G/5.00G [00:43<01:22, 45.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  26%|███████████▍                               | 1.31G/4.94G [00:44<01:27, 41.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  27%|███████████▋                               | 1.23G/4.54G [00:44<01:32, 35.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  27%|███████████▊                               | 1.24G/4.54G [00:44<01:14, 44.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  24%|██████████▌                                | 1.22G/5.00G [00:44<02:13, 28.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  27%|███████████▍                               | 1.31G/4.94G [00:44<01:58, 30.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  27%|███████████▍                               | 1.32G/4.94G [00:44<01:40, 36.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  28%|███████████▊                               | 1.25G/4.54G [00:44<01:38, 33.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  28%|███████████▉                               | 1.26G/4.54G [00:44<01:08, 47.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  27%|███████████▌                               | 1.33G/4.94G [00:44<01:57, 30.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  27%|███████████▋                               | 1.34G/4.94G [00:45<01:26, 41.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  28%|████████████                               | 1.27G/4.54G [00:45<01:30, 36.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  25%|██████████▋                                | 1.25G/5.00G [00:45<02:13, 28.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  28%|████████████                               | 1.28G/4.54G [00:45<01:22, 39.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  25%|██████████▊                                | 1.25G/5.00G [00:45<02:01, 30.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  27%|███████████▊                               | 1.36G/4.94G [00:45<01:23, 43.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  28%|████████████▏                              | 1.28G/4.54G [00:45<01:54, 28.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  28%|███████████▊                               | 1.36G/4.94G [00:45<01:41, 35.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  28%|███████████▉                               | 1.37G/4.94G [00:45<01:23, 42.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  28%|███████████▉                               | 1.38G/4.94G [00:46<01:53, 31.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  28%|████████████                               | 1.38G/4.94G [00:46<01:36, 36.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  28%|████████████                               | 1.39G/4.94G [00:46<01:26, 41.0MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  28%|████████████▏                              | 1.40G/4.94G [00:46<01:46, 33.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  28%|████████████▏                              | 1.40G/4.94G [00:46<01:27, 40.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  26%|███████████▏                               | 1.30G/5.00G [00:46<01:48, 33.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  29%|████████████▎                              | 1.30G/4.54G [00:46<03:14, 16.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  26%|███████████▏                               | 1.31G/5.00G [00:46<01:45, 35.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  29%|████████████▍                              | 1.31G/4.54G [00:46<02:41, 20.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  29%|████████████▎                              | 1.42G/4.94G [00:47<01:21, 43.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  26%|███████████▎                               | 1.32G/5.00G [00:47<02:19, 26.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  29%|████████████▍                              | 1.44G/4.94G [00:47<01:20, 43.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  27%|███████████▍                               | 1.33G/5.00G [00:47<02:05, 29.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  29%|████████████▌                              | 1.45G/4.94G [00:48<01:22, 42.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  27%|███████████▌                               | 1.35G/5.00G [00:48<02:01, 30.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  30%|████████████▊                              | 1.47G/4.94G [00:48<01:17, 44.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  29%|████████████▍                              | 1.31G/4.54G [00:48<05:22, 9.99MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  29%|████████████▌                              | 1.32G/4.54G [00:48<03:32, 15.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  27%|███████████▋                               | 1.36G/5.00G [00:48<01:44, 34.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  30%|████████████▉                              | 1.48G/4.94G [00:48<01:23, 41.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  29%|████████████▌                              | 1.33G/4.54G [00:48<03:32, 15.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  30%|█████████████                              | 1.50G/4.94G [00:49<01:15, 45.3MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  30%|████████████▊                              | 1.35G/4.54G [00:49<02:11, 24.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  30%|████████████▊                              | 1.36G/4.54G [00:49<01:42, 31.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  30%|█████████████                              | 1.51G/4.94G [00:49<01:39, 34.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  28%|███████████▉                               | 1.39G/5.00G [00:49<02:15, 26.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  31%|█████████████▏                             | 1.51G/4.94G [00:49<01:32, 37.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  31%|█████████████▏                             | 1.52G/4.94G [00:49<01:30, 38.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  30%|█████████████                              | 1.38G/4.54G [00:49<01:30, 35.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  31%|█████████████▏                             | 1.52G/4.94G [00:50<01:54, 29.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  28%|████████████                               | 1.40G/5.00G [00:50<02:03, 29.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  31%|█████████████▎                             | 1.53G/4.94G [00:50<01:46, 32.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  31%|█████████████                              | 1.39G/4.54G [00:50<01:40, 31.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  31%|█████████████▎                             | 1.53G/4.94G [00:50<01:42, 33.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  31%|█████████████▎                             | 1.54G/4.94G [00:50<01:36, 35.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  28%|████████████▏                              | 1.41G/5.00G [00:50<02:13, 26.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  28%|████████████▏                              | 1.42G/5.00G [00:50<01:36, 37.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  31%|█████████████▍                             | 1.54G/4.94G [00:50<02:21, 24.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  31%|█████████████▍                             | 1.55G/4.94G [00:50<01:50, 30.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  31%|█████████████▍                             | 1.55G/4.94G [00:50<01:34, 35.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  29%|████████████▎                              | 1.43G/5.00G [00:51<02:18, 25.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  31%|█████████████▌                             | 1.56G/4.94G [00:51<02:04, 27.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  32%|█████████████▌                             | 1.56G/4.94G [00:51<01:48, 31.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  32%|█████████████▌                             | 1.57G/4.94G [00:51<01:35, 35.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  29%|████████████▎                              | 1.43G/5.00G [00:51<03:12, 18.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  29%|████████████▎                              | 1.44G/5.00G [00:51<02:29, 23.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  32%|█████████████▋                             | 1.57G/4.94G [00:51<02:16, 24.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  32%|█████████████▋                             | 1.58G/4.94G [00:51<01:54, 29.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  32%|█████████████▊                             | 1.58G/4.94G [00:51<01:37, 34.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  29%|████████████▍                              | 1.44G/5.00G [00:52<03:12, 18.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  32%|█████████████▊                             | 1.59G/4.94G [00:52<02:00, 28.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  29%|████████████▍                              | 1.45G/5.00G [00:52<02:29, 23.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  32%|█████████████▊                             | 1.59G/4.94G [00:52<01:54, 29.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  29%|████████████▌                              | 1.45G/5.00G [00:52<02:20, 25.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  32%|█████████████▉                             | 1.60G/4.94G [00:52<01:37, 34.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  29%|████████████▌                              | 1.46G/5.00G [00:52<03:01, 19.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  32%|█████████████▊                             | 1.46G/4.54G [00:52<02:09, 23.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  32%|█████████████▉                             | 1.47G/4.54G [00:52<01:31, 33.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  29%|████████████▌                              | 1.46G/5.00G [00:52<02:20, 25.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  32%|█████████████▉                             | 1.47G/4.54G [00:52<01:18, 39.0MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  33%|██████████████                             | 1.61G/4.94G [00:53<01:50, 30.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  33%|█████████████▉                             | 1.48G/4.54G [00:53<01:45, 29.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  29%|████████████▋                              | 1.47G/5.00G [00:53<02:48, 20.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  33%|██████████████                             | 1.48G/4.54G [00:53<01:22, 37.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  30%|████████████▋                              | 1.48G/5.00G [00:53<02:07, 27.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  30%|████████████▊                              | 1.49G/5.00G [00:53<01:36, 36.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  33%|██████████████                             | 1.49G/4.54G [00:53<02:10, 23.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  30%|████████████▊                              | 1.49G/5.00G [00:53<02:05, 28.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  33%|██████████████▏                            | 1.50G/4.54G [00:53<01:30, 33.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  30%|████████████▉                              | 1.50G/5.00G [00:53<01:47, 32.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  30%|████████████▉                              | 1.50G/5.00G [00:53<01:37, 35.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  33%|██████████████▏                            | 1.50G/4.54G [00:54<02:03, 24.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  33%|██████████████                             | 1.62G/4.94G [00:54<04:37, 12.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  33%|██████████████▎                            | 1.51G/4.54G [00:54<01:29, 34.0MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  33%|██████████████                             | 1.62G/4.94G [00:54<03:58, 13.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  30%|█████████████                              | 1.52G/5.00G [00:54<01:48, 32.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  33%|██████████████▏                            | 1.62G/4.94G [00:54<03:24, 16.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  33%|██████████████▏                            | 1.63G/4.94G [00:54<02:45, 20.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  34%|██████████████▍                            | 1.52G/4.54G [00:54<01:45, 28.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  30%|█████████████                              | 1.52G/5.00G [00:54<02:18, 25.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  33%|██████████████▏                            | 1.63G/4.94G [00:54<02:56, 18.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  31%|█████████████▏                             | 1.53G/5.00G [00:54<02:00, 28.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  33%|██████████████▏                            | 1.64G/4.94G [00:55<02:35, 21.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  33%|██████████████▎                            | 1.64G/4.94G [00:55<02:18, 23.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  33%|██████████████▎                            | 1.65G/4.94G [00:55<01:42, 32.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  34%|██████████████▌                            | 1.54G/4.54G [00:55<01:57, 25.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  31%|█████████████▏                             | 1.54G/5.00G [00:55<02:16, 25.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  34%|██████████████▋                            | 1.55G/4.54G [00:55<01:30, 33.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  31%|█████████████▎                             | 1.54G/5.00G [00:55<01:51, 30.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  34%|██████████████▍                            | 1.66G/4.94G [00:55<01:44, 31.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  34%|██████████████▋                            | 1.55G/4.54G [00:55<01:59, 25.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  34%|██████████████▊                            | 1.57G/4.54G [00:55<01:10, 42.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  31%|█████████████▎                             | 1.55G/5.00G [00:55<02:13, 25.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  34%|██████████████▍                            | 1.67G/4.94G [00:56<02:17, 23.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  34%|██████████████▌                            | 1.67G/4.94G [00:56<01:42, 32.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  34%|██████████████▌                            | 1.68G/4.94G [00:56<01:33, 34.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  35%|███████████████                            | 1.58G/4.54G [00:56<01:08, 42.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  31%|█████████████▍                             | 1.57G/5.00G [00:56<02:10, 26.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  34%|██████████████▋                            | 1.68G/4.94G [00:56<02:05, 25.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  35%|███████████████                            | 1.59G/4.54G [00:56<01:35, 31.0MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  34%|██████████████▋                            | 1.69G/4.94G [00:56<01:42, 31.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  35%|███████████████                            | 1.59G/4.54G [00:56<01:29, 33.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  34%|██████████████▋                            | 1.69G/4.94G [00:56<01:38, 33.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  35%|███████████████▏                           | 1.60G/4.54G [00:56<01:24, 34.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  32%|█████████████▋                             | 1.59G/5.00G [00:56<01:33, 36.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  34%|██████████████▊                            | 1.70G/4.94G [00:57<02:03, 26.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  35%|██████████████▊                            | 1.71G/4.94G [00:57<01:25, 37.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  35%|███████████████▏                           | 1.61G/4.54G [00:57<01:26, 33.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  32%|█████████████▊                             | 1.60G/5.00G [00:57<01:59, 28.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  36%|███████████████▎                           | 1.61G/4.54G [00:57<01:21, 35.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  35%|██████████████▉                            | 1.72G/4.94G [00:57<01:23, 38.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  36%|███████████████▎                           | 1.62G/4.54G [00:57<01:52, 26.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  32%|█████████████▉                             | 1.62G/5.00G [00:57<02:00, 28.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  36%|███████████████▍                           | 1.63G/4.54G [00:57<01:26, 33.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  32%|█████████████▉                             | 1.62G/5.00G [00:57<01:32, 36.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  36%|███████████████▍                           | 1.63G/4.54G [00:57<01:19, 36.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  35%|███████████████                            | 1.73G/4.94G [00:58<01:32, 34.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  33%|██████████████                             | 1.63G/5.00G [00:58<01:52, 29.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  33%|██████████████▏                            | 1.64G/5.00G [00:58<01:20, 41.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  35%|███████████████▏                           | 1.74G/4.94G [00:58<01:36, 33.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  35%|███████████████▏                           | 1.75G/4.94G [00:58<01:26, 36.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  36%|███████████████▌                           | 1.65G/4.54G [00:58<01:36, 29.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  36%|███████████████▎                           | 1.76G/4.94G [00:58<01:20, 39.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  33%|██████████████▏                            | 1.65G/5.00G [00:58<01:34, 35.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  36%|███████████████▎                           | 1.76G/4.94G [00:58<01:49, 29.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  36%|███████████████▎                           | 1.77G/4.94G [00:59<01:27, 36.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  36%|███████████████▋                           | 1.66G/4.54G [00:59<01:38, 29.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  36%|███████████████▍                           | 1.77G/4.94G [00:59<01:18, 40.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  37%|███████████████▋                           | 1.66G/4.54G [00:59<01:31, 31.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  33%|██████████████▎                            | 1.67G/5.00G [00:59<01:45, 31.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  36%|███████████████▍                           | 1.78G/4.94G [00:59<01:44, 30.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  36%|███████████████▌                           | 1.79G/4.94G [00:59<01:11, 44.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  34%|██████████████▍                            | 1.68G/5.00G [00:59<01:49, 30.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  37%|███████████████▊                           | 1.67G/4.54G [00:59<01:35, 30.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  34%|██████████████▌                            | 1.69G/5.00G [00:59<01:31, 36.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  37%|███████████████▉                           | 1.68G/4.54G [00:59<01:26, 33.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  37%|███████████████▋                           | 1.81G/4.94G [00:59<01:11, 43.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  37%|███████████████▉                           | 1.68G/4.54G [01:00<01:56, 24.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  34%|██████████████▌                            | 1.70G/5.00G [01:00<01:48, 30.3MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  37%|████████████████                           | 1.69G/4.54G [01:00<01:21, 34.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  34%|██████████████▋                            | 1.70G/5.00G [01:00<01:36, 34.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  34%|██████████████▋                            | 1.71G/5.00G [01:00<01:27, 37.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  37%|████████████████                           | 1.70G/4.54G [01:00<01:55, 24.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  37%|███████████████▊                           | 1.81G/4.94G [01:00<02:09, 24.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  38%|████████████████▏                          | 1.71G/4.54G [01:00<01:21, 34.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  34%|██████████████▊                            | 1.72G/5.00G [01:00<01:37, 33.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  35%|██████████████▊                            | 1.73G/5.00G [01:00<01:25, 38.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  37%|███████████████▊                           | 1.82G/4.94G [01:00<02:25, 21.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  37%|███████████████▊                           | 1.82G/4.94G [01:00<01:56, 26.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  35%|██████████████▉                            | 1.73G/5.00G [01:01<02:02, 26.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  38%|████████████████▎                          | 1.72G/4.54G [01:01<01:13, 38.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  35%|██████████████▉                            | 1.74G/5.00G [01:01<01:40, 32.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  35%|██████████████▉                            | 1.74G/5.00G [01:01<01:28, 36.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  37%|███████████████▉                           | 1.83G/4.94G [01:01<02:42, 19.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  38%|████████████████▍                          | 1.74G/4.54G [01:01<01:14, 37.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  37%|███████████████▉                           | 1.83G/4.94G [01:01<02:21, 22.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  35%|███████████████                            | 1.75G/5.00G [01:01<01:53, 28.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  37%|███████████████▉                           | 1.84G/4.94G [01:01<02:11, 23.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  35%|███████████████                            | 1.75G/5.00G [01:01<01:44, 31.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  37%|████████████████                           | 1.84G/4.94G [01:02<02:41, 19.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  35%|███████████████▏                           | 1.76G/5.00G [01:02<01:59, 27.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  37%|████████████████                           | 1.84G/4.94G [01:02<02:15, 22.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  37%|████████████████                           | 1.85G/4.94G [01:02<02:05, 24.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  37%|████████████████                           | 1.85G/4.94G [01:02<01:55, 26.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  35%|███████████████▎                           | 1.77G/5.00G [01:02<01:26, 37.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  39%|████████████████▋                          | 1.76G/4.54G [01:02<01:51, 25.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  38%|████████████████▏                          | 1.86G/4.94G [01:02<02:21, 21.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  38%|████████████████▏                          | 1.86G/4.94G [01:02<01:53, 27.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  38%|████████████████▏                          | 1.87G/4.94G [01:02<01:35, 32.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  38%|████████████████▎                          | 1.87G/4.94G [01:02<01:24, 36.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  39%|████████████████▊                          | 1.78G/4.54G [01:02<01:32, 29.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  36%|███████████████▍                           | 1.79G/5.00G [01:03<01:47, 29.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  39%|████████████████▉                          | 1.79G/4.54G [01:03<01:10, 39.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  38%|████████████████▎                          | 1.88G/4.94G [01:03<02:22, 21.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  38%|████████████████▎                          | 1.88G/4.94G [01:03<02:08, 23.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  38%|████████████████▍                          | 1.88G/4.94G [01:03<01:54, 26.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  38%|████████████████▍                          | 1.89G/4.94G [01:03<01:39, 30.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  36%|███████████████▌                           | 1.82G/5.00G [01:03<01:28, 36.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  38%|████████████████▍                          | 1.89G/4.94G [01:03<02:02, 24.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  38%|████████████████▌                          | 1.90G/4.94G [01:04<01:27, 34.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  40%|█████████████████▎                         | 1.82G/4.54G [01:04<01:36, 28.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  36%|███████████████▋                           | 1.82G/5.00G [01:04<02:22, 22.3MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  40%|█████████████████▎                         | 1.83G/4.54G [01:04<01:12, 37.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  39%|████████████████▌                          | 1.91G/4.94G [01:04<02:08, 23.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  39%|████████████████▌                          | 1.91G/4.94G [01:04<02:03, 24.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  41%|█████████████████▍                         | 1.84G/4.54G [01:04<01:10, 38.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  39%|████████████████▋                          | 1.91G/4.94G [01:04<02:01, 25.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  39%|████████████████▋                          | 1.92G/4.94G [01:04<01:52, 26.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  39%|████████████████▊                          | 1.93G/4.94G [01:05<01:27, 34.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  39%|████████████████▊                          | 1.93G/4.94G [01:05<01:19, 37.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  37%|███████████████▉                           | 1.85G/5.00G [01:05<02:11, 23.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  41%|█████████████████▌                         | 1.86G/4.54G [01:05<01:36, 27.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  39%|████████████████▊                          | 1.94G/4.94G [01:05<01:52, 26.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  39%|████████████████▉                          | 1.95G/4.94G [01:05<01:12, 41.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  37%|████████████████                           | 1.86G/5.00G [01:05<01:44, 30.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  41%|█████████████████▋                         | 1.87G/4.54G [01:05<01:38, 27.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  40%|█████████████████                          | 1.96G/4.94G [01:05<01:14, 40.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  37%|████████████████                           | 1.87G/5.00G [01:06<02:02, 25.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  40%|█████████████████▏                         | 1.97G/4.94G [01:06<01:27, 34.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  40%|█████████████████▏                         | 1.98G/4.94G [01:06<01:18, 37.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  40%|█████████████████▏                         | 1.98G/4.94G [01:06<01:12, 41.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  38%|████████████████▎                          | 1.89G/5.00G [01:06<01:43, 30.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  40%|█████████████████▎                         | 1.99G/4.94G [01:06<01:29, 32.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  40%|█████████████████▎                         | 1.99G/4.94G [01:06<01:12, 40.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  40%|█████████████████▍                         | 2.00G/4.94G [01:06<01:06, 44.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  42%|██████████████████▏                        | 1.92G/4.54G [01:06<01:10, 37.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  38%|████████████████▍                          | 1.90G/5.00G [01:06<01:48, 28.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  41%|█████████████████▌                         | 2.02G/4.94G [01:07<01:01, 47.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  38%|████████████████▌                          | 1.92G/5.00G [01:07<01:36, 31.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  42%|██████████████████▏                        | 1.92G/4.54G [01:07<02:00, 21.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  39%|████████████████▌                          | 1.93G/5.00G [01:07<01:29, 34.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  41%|█████████████████▌                         | 2.02G/4.94G [01:07<01:25, 34.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  43%|██████████████████▎                        | 1.93G/4.54G [01:07<01:35, 27.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  41%|█████████████████▋                         | 2.03G/4.94G [01:07<01:20, 36.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  39%|████████████████▋                          | 1.94G/5.00G [01:07<01:50, 27.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  43%|██████████████████▎                        | 1.94G/4.54G [01:07<02:07, 20.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  41%|█████████████████▋                         | 2.04G/4.94G [01:08<01:41, 28.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  41%|█████████████████▋                         | 2.04G/4.94G [01:08<01:36, 30.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  39%|████████████████▊                          | 1.95G/5.00G [01:08<01:24, 36.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  41%|█████████████████▊                         | 2.04G/4.94G [01:08<01:30, 31.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  39%|████████████████▊                          | 1.95G/5.00G [01:08<01:53, 26.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  41%|█████████████████▊                         | 2.05G/4.94G [01:08<01:52, 25.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  42%|█████████████████▊                         | 2.05G/4.94G [01:08<01:39, 29.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  43%|██████████████████▌                        | 1.96G/4.54G [01:08<01:23, 30.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  39%|████████████████▉                          | 1.97G/5.00G [01:08<01:24, 35.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  42%|█████████████████▉                         | 2.06G/4.94G [01:09<01:57, 24.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  42%|██████████████████                         | 2.07G/4.94G [01:09<01:16, 37.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  42%|██████████████████                         | 2.08G/4.94G [01:09<01:12, 39.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  39%|████████████████▉                          | 1.97G/5.00G [01:09<03:00, 16.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  40%|█████████████████                          | 1.98G/5.00G [01:09<02:03, 24.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  44%|██████████████████▊                        | 1.98G/4.54G [01:09<01:48, 23.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  44%|██████████████████▉                        | 2.00G/4.54G [01:09<01:04, 39.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  40%|█████████████████                          | 1.98G/5.00G [01:09<02:28, 20.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  42%|██████████████████                         | 2.08G/4.94G [01:10<03:11, 14.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  42%|██████████████████▏                        | 2.09G/4.94G [01:10<02:08, 22.3MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  44%|██████████████████▉                        | 2.00G/4.54G [01:10<01:34, 26.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  40%|█████████████████▎                         | 2.01G/5.00G [01:10<01:35, 31.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  44%|███████████████████                        | 2.01G/4.54G [01:10<01:26, 29.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  40%|█████████████████▎                         | 2.01G/5.00G [01:10<01:31, 32.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  43%|██████████████████▎                        | 2.11G/4.94G [01:10<01:31, 31.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  40%|█████████████████▎                         | 2.02G/5.00G [01:10<01:44, 28.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  44%|███████████████████                        | 2.02G/4.54G [01:10<01:52, 22.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  41%|█████████████████▍                         | 2.03G/5.00G [01:10<01:18, 37.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  45%|███████████████████▏                       | 2.03G/4.54G [01:10<01:20, 31.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  43%|██████████████████▍                        | 2.12G/4.94G [01:11<01:18, 35.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  41%|█████████████████▍                         | 2.03G/5.00G [01:11<01:52, 26.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  41%|█████████████████▌                         | 2.04G/5.00G [01:11<01:11, 41.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  45%|███████████████████▎                       | 2.04G/4.54G [01:11<01:29, 28.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  43%|██████████████████▌                        | 2.14G/4.94G [01:11<01:24, 33.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  43%|██████████████████▋                        | 2.14G/4.94G [01:11<01:10, 39.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  41%|█████████████████▋                         | 2.06G/5.00G [01:11<01:22, 35.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  45%|███████████████████▍                       | 2.05G/4.54G [01:11<01:32, 26.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  41%|█████████████████▋                         | 2.06G/5.00G [01:11<01:08, 43.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  44%|██████████████████▊                        | 2.16G/4.94G [01:12<01:10, 39.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  41%|█████████████████▊                         | 2.07G/5.00G [01:12<01:35, 30.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  45%|███████████████████▌                       | 2.06G/4.54G [01:12<01:23, 29.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  42%|█████████████████▊                         | 2.08G/5.00G [01:12<01:19, 37.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  46%|███████████████████▋                       | 2.07G/4.54G [01:12<01:01, 40.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  44%|██████████████████▉                        | 2.17G/4.94G [01:12<01:07, 40.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  42%|█████████████████▉                         | 2.08G/5.00G [01:12<01:49, 26.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  46%|███████████████████▋                       | 2.09G/4.54G [01:12<01:13, 33.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  42%|█████████████████▉                         | 2.09G/5.00G [01:12<01:17, 37.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  46%|███████████████████▊                       | 2.09G/4.54G [01:12<01:05, 37.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  44%|███████████████████                        | 2.19G/4.94G [01:13<01:06, 41.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  42%|██████████████████                         | 2.10G/5.00G [01:13<01:28, 32.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  46%|███████████████████▊                       | 2.10G/4.54G [01:13<01:28, 27.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  42%|██████████████████▏                        | 2.11G/5.00G [01:13<01:13, 39.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  46%|███████████████████▉                       | 2.11G/4.54G [01:13<01:03, 38.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  44%|███████████████████                        | 2.20G/4.94G [01:13<01:29, 30.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  45%|███████████████████▏                       | 2.21G/4.94G [01:13<01:07, 40.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  45%|███████████████████▎                       | 2.22G/4.94G [01:13<01:02, 43.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  43%|██████████████████▎                        | 2.13G/5.00G [01:13<01:42, 28.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  47%|████████████████████                       | 2.12G/4.54G [01:14<02:03, 19.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  43%|██████████████████▍                        | 2.14G/5.00G [01:14<01:16, 37.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  47%|████████████████████                       | 2.12G/4.54G [01:14<01:46, 22.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  45%|███████████████████▍                       | 2.23G/4.94G [01:14<01:26, 31.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  45%|███████████████████▍                       | 2.23G/4.94G [01:14<01:19, 34.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  43%|██████████████████▍                        | 2.15G/5.00G [01:14<01:31, 31.3MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  47%|████████████████████▏                      | 2.13G/4.54G [01:14<01:54, 21.0MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  45%|███████████████████▍                       | 2.24G/4.94G [01:14<01:28, 30.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  45%|███████████████████▌                       | 2.25G/4.94G [01:14<01:17, 34.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  46%|███████████████████▌                       | 2.25G/4.94G [01:14<01:06, 40.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  43%|██████████████████▌                        | 2.16G/5.00G [01:14<01:43, 27.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  43%|██████████████████▋                        | 2.17G/5.00G [01:15<01:12, 38.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  46%|███████████████████▋                       | 2.26G/4.94G [01:15<01:31, 29.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  46%|███████████████████▋                       | 2.26G/4.94G [01:15<01:17, 34.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  46%|███████████████████▋                       | 2.27G/4.94G [01:15<01:07, 39.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  44%|██████████████████▋                        | 2.18G/5.00G [01:15<01:32, 30.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  44%|██████████████████▊                        | 2.18G/5.00G [01:15<01:17, 36.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  46%|███████████████████▊                       | 2.27G/4.94G [01:15<01:26, 31.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  46%|███████████████████▊                       | 2.28G/4.94G [01:15<01:16, 34.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  46%|███████████████████▉                       | 2.29G/4.94G [01:15<01:05, 40.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  44%|██████████████████▊                        | 2.19G/5.00G [01:15<01:33, 30.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  46%|███████████████████▉                       | 2.29G/4.94G [01:16<01:25, 31.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  47%|████████████████████                       | 2.30G/4.94G [01:16<01:04, 41.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  44%|██████████████████▉                        | 2.21G/5.00G [01:16<01:21, 34.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  48%|████████████████████▋                      | 2.18G/4.54G [01:16<01:18, 30.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  44%|███████████████████                        | 2.21G/5.00G [01:16<01:13, 37.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  48%|████████████████████▋                      | 2.19G/4.54G [01:16<01:10, 33.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  47%|████████████████████                       | 2.30G/4.94G [01:16<01:39, 26.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  47%|████████████████████▏                      | 2.31G/4.94G [01:16<01:12, 36.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  45%|███████████████████▏                       | 2.23G/5.00G [01:16<01:24, 32.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  47%|████████████████████▏                      | 2.32G/4.94G [01:16<01:07, 38.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  45%|███████████████████▏                       | 2.23G/5.00G [01:16<01:20, 34.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  49%|████████████████████▉                      | 2.21G/4.54G [01:16<01:09, 33.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  45%|███████████████████▏                       | 2.23G/5.00G [01:16<01:15, 36.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  47%|████████████████████▎                      | 2.34G/4.94G [01:17<00:58, 44.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  45%|███████████████████▎                       | 2.24G/5.00G [01:17<01:30, 30.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  49%|████████████████████▉                      | 2.21G/4.54G [01:17<01:47, 21.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  45%|███████████████████▎                       | 2.25G/5.00G [01:17<01:15, 36.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  49%|█████████████████████                      | 2.22G/4.54G [01:17<01:14, 31.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  47%|████████████████████▎                      | 2.34G/4.94G [01:17<01:34, 27.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  45%|███████████████████▍                       | 2.26G/5.00G [01:17<01:39, 27.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  47%|████████████████████▍                      | 2.35G/4.94G [01:17<01:20, 32.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  45%|███████████████████▍                       | 2.26G/5.00G [01:17<01:19, 34.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  49%|█████████████████████▏                     | 2.23G/4.54G [01:17<01:15, 30.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  45%|███████████████████▍                       | 2.27G/5.00G [01:17<01:17, 35.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  48%|████████████████████▍                      | 2.35G/4.94G [01:18<01:45, 24.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  48%|████████████████████▌                      | 2.36G/4.94G [01:18<01:23, 31.0MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  48%|████████████████████▌                      | 2.37G/4.94G [01:18<01:13, 34.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  46%|███████████████████▋                       | 2.28G/5.00G [01:18<01:08, 39.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  49%|█████████████████████▏                     | 2.24G/4.54G [01:18<01:52, 20.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  48%|████████████████████▌                      | 2.37G/4.94G [01:18<01:30, 28.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  48%|████████████████████▋                      | 2.38G/4.94G [01:18<01:09, 36.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  46%|███████████████████▋                       | 2.30G/5.00G [01:18<01:17, 35.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  50%|█████████████████████▎                     | 2.26G/4.54G [01:18<01:24, 27.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  46%|███████████████████▊                       | 2.30G/5.00G [01:18<01:11, 37.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  50%|█████████████████████▍                     | 2.26G/4.54G [01:18<01:03, 35.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  48%|████████████████████▊                      | 2.39G/4.94G [01:19<01:02, 40.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  46%|███████████████████▊                       | 2.30G/5.00G [01:19<01:39, 27.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  46%|███████████████████▉                       | 2.31G/5.00G [01:19<01:15, 35.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  50%|█████████████████████▌                     | 2.28G/4.54G [01:19<01:13, 30.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  49%|████████████████████▉                      | 2.40G/4.94G [01:19<01:14, 34.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  49%|████████████████████▉                      | 2.41G/4.94G [01:19<01:07, 37.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  49%|████████████████████▉                      | 2.41G/4.94G [01:19<01:02, 40.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  47%|███████████████████▉                       | 2.33G/5.00G [01:19<01:24, 31.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  50%|█████████████████████▋                     | 2.29G/4.54G [01:19<01:16, 29.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  49%|█████████████████████                      | 2.42G/4.94G [01:19<01:22, 30.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  49%|█████████████████████                      | 2.42G/4.94G [01:19<01:16, 32.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  49%|█████████████████████                      | 2.42G/4.94G [01:20<01:11, 35.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  47%|████████████████████                       | 2.34G/5.00G [01:20<01:52, 23.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  49%|█████████████████████▏                     | 2.44G/4.94G [01:20<01:05, 38.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  51%|█████████████████████▊                     | 2.31G/4.54G [01:20<02:06, 17.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  51%|█████████████████████▉                     | 2.32G/4.54G [01:20<01:13, 30.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  50%|█████████████████████▎                     | 2.45G/4.94G [01:20<01:15, 33.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  50%|█████████████████████▎                     | 2.45G/4.94G [01:20<01:05, 38.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  50%|█████████████████████▍                     | 2.46G/4.94G [01:20<00:58, 42.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  51%|██████████████████████                     | 2.32G/4.54G [01:20<01:21, 27.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  50%|█████████████████████▌                     | 2.48G/4.94G [01:21<00:55, 44.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  47%|████████████████████▎                      | 2.37G/5.00G [01:21<02:12, 19.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  51%|██████████████████████                     | 2.34G/4.54G [01:21<01:27, 25.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  48%|████████████████████▍                      | 2.38G/5.00G [01:21<01:39, 26.3MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  52%|██████████████████████▏                    | 2.35G/4.54G [01:21<01:02, 35.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  48%|████████████████████▍                      | 2.38G/5.00G [01:21<01:26, 30.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  50%|█████████████████████▋                     | 2.49G/4.94G [01:21<00:56, 43.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  48%|████████████████████▌                      | 2.39G/5.00G [01:21<01:43, 25.3MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  52%|██████████████████████▎                    | 2.36G/4.54G [01:21<01:11, 30.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  48%|████████████████████▌                      | 2.39G/5.00G [01:22<01:24, 30.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  52%|██████████████████████▎                    | 2.36G/4.54G [01:22<01:03, 34.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  48%|████████████████████▌                      | 2.40G/5.00G [01:22<01:14, 34.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  51%|█████████████████████▊                     | 2.51G/4.94G [01:22<00:59, 41.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  48%|████████████████████▋                      | 2.40G/5.00G [01:22<01:35, 27.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  52%|██████████████████████▍                    | 2.37G/4.54G [01:22<01:16, 28.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  48%|████████████████████▋                      | 2.41G/5.00G [01:22<01:13, 35.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  52%|██████████████████████▌                    | 2.38G/4.54G [01:22<01:04, 33.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  51%|█████████████████████▉                     | 2.53G/4.94G [01:22<01:00, 40.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  48%|████████████████████▊                      | 2.42G/5.00G [01:22<01:21, 31.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  49%|████████████████████▉                      | 2.43G/5.00G [01:22<00:57, 44.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  53%|██████████████████████▌                    | 2.38G/4.54G [01:23<01:47, 20.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  51%|██████████████████████                     | 2.53G/4.94G [01:23<01:26, 27.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  49%|████████████████████▉                      | 2.44G/5.00G [01:23<01:21, 31.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  51%|██████████████████████                     | 2.54G/4.94G [01:23<01:18, 30.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  49%|█████████████████████                      | 2.45G/5.00G [01:23<01:08, 37.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  53%|██████████████████████▊                    | 2.40G/4.54G [01:23<01:16, 28.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  51%|██████████████████████▏                    | 2.54G/4.94G [01:23<01:31, 26.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  52%|██████████████████████▏                    | 2.55G/4.94G [01:23<01:03, 37.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  49%|█████████████████████                      | 2.46G/5.00G [01:23<01:18, 32.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  53%|██████████████████████▉                    | 2.42G/4.54G [01:23<01:04, 32.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  49%|█████████████████████▏                     | 2.46G/5.00G [01:23<01:02, 40.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  52%|██████████████████████▎                    | 2.57G/4.94G [01:24<01:06, 35.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  52%|██████████████████████▍                    | 2.57G/4.94G [01:24<00:58, 40.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  49%|█████████████████████▎                     | 2.47G/5.00G [01:24<01:10, 35.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  54%|███████████████████████                    | 2.43G/4.54G [01:24<01:17, 27.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  52%|██████████████████████▍                    | 2.59G/4.94G [01:24<01:01, 38.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  52%|██████████████████████▌                    | 2.59G/4.94G [01:24<00:54, 43.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  50%|█████████████████████▍                     | 2.49G/5.00G [01:24<01:10, 35.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  54%|███████████████████████▏                   | 2.45G/4.54G [01:24<01:08, 30.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  53%|██████████████████████▌                    | 2.60G/4.94G [01:25<01:12, 32.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  53%|██████████████████████▋                    | 2.60G/4.94G [01:25<01:03, 36.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  50%|█████████████████████▌                     | 2.50G/5.00G [01:25<01:02, 39.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  50%|█████████████████████▌                     | 2.51G/5.00G [01:25<00:57, 43.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  54%|███████████████████████▎                   | 2.46G/4.54G [01:25<01:10, 29.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  53%|██████████████████████▊                    | 2.62G/4.94G [01:25<00:56, 41.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  50%|█████████████████████▋                     | 2.51G/5.00G [01:25<01:17, 31.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  50%|█████████████████████▋                     | 2.52G/5.00G [01:25<01:09, 35.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  55%|███████████████████████▌                   | 2.48G/4.54G [01:25<00:59, 34.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  51%|█████████████████████▋                     | 2.53G/5.00G [01:25<00:55, 44.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  53%|██████████████████████▉                    | 2.64G/4.94G [01:26<00:54, 42.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  51%|█████████████████████▊                     | 2.53G/5.00G [01:26<01:22, 29.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  55%|███████████████████████▋                   | 2.50G/4.54G [01:26<01:07, 30.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  51%|█████████████████████▊                     | 2.54G/5.00G [01:26<01:09, 35.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  55%|███████████████████████▋                   | 2.51G/4.54G [01:26<00:51, 39.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  54%|███████████████████████                    | 2.65G/4.94G [01:26<00:57, 40.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  51%|█████████████████████▉                     | 2.54G/5.00G [01:26<01:36, 25.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  51%|█████████████████████▉                     | 2.56G/5.00G [01:26<01:01, 39.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  54%|███████████████████████▏                   | 2.66G/4.94G [01:26<01:00, 37.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  54%|███████████████████████▏                   | 2.67G/4.94G [01:26<00:52, 43.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  56%|███████████████████████▉                   | 2.53G/4.54G [01:26<00:59, 33.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  51%|██████████████████████                     | 2.56G/5.00G [01:27<01:18, 31.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  54%|███████████████████████▎                   | 2.68G/4.94G [01:27<01:05, 34.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  54%|███████████████████████▎                   | 2.68G/4.94G [01:27<00:54, 41.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  56%|████████████████████████                   | 2.54G/4.54G [01:27<01:02, 32.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  56%|████████████████████████                   | 2.54G/4.54G [01:27<00:54, 36.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  52%|██████████████████████▏                    | 2.58G/5.00G [01:27<01:24, 28.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  55%|███████████████████████▍                   | 2.69G/4.94G [01:27<00:59, 37.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  55%|███████████████████████▌                   | 2.70G/4.94G [01:27<00:48, 46.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  56%|████████████████████████▏                  | 2.55G/4.54G [01:27<00:58, 34.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  52%|██████████████████████▎                    | 2.59G/5.00G [01:27<01:15, 31.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  55%|███████████████████████▌                   | 2.71G/4.94G [01:28<00:59, 37.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  55%|███████████████████████▌                   | 2.71G/4.94G [01:28<00:54, 41.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  55%|███████████████████████▋                   | 2.72G/4.94G [01:28<00:51, 43.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  57%|████████████████████████▎                  | 2.57G/4.54G [01:28<00:51, 38.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  52%|██████████████████████▍                    | 2.61G/5.00G [01:28<01:24, 28.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  55%|███████████████████████▊                   | 2.73G/4.94G [01:28<01:01, 36.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  57%|████████████████████████▍                  | 2.58G/4.54G [01:28<01:11, 27.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  56%|███████████████████████▉                   | 2.75G/4.94G [01:29<00:48, 45.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  57%|████████████████████████▌                  | 2.60G/4.54G [01:29<00:55, 35.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  53%|██████████████████████▌                    | 2.63G/5.00G [01:29<01:47, 22.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  57%|████████████████████████▋                  | 2.61G/4.54G [01:29<00:41, 46.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  56%|███████████████████████▉                   | 2.75G/4.94G [01:29<01:09, 31.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  56%|████████████████████████                   | 2.76G/4.94G [01:29<00:54, 39.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  58%|████████████████████████▊                  | 2.62G/4.54G [01:29<00:46, 40.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  53%|██████████████████████▋                    | 2.64G/5.00G [01:29<01:29, 26.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  56%|████████████████████████                   | 2.77G/4.94G [01:29<01:06, 32.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  56%|████████████████████████▏                  | 2.77G/4.94G [01:29<00:56, 38.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  56%|████████████████████████▏                  | 2.78G/4.94G [01:29<00:47, 45.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  58%|████████████████████████▉                  | 2.63G/4.54G [01:29<00:49, 38.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  53%|██████████████████████▊                    | 2.66G/5.00G [01:30<01:17, 30.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  56%|████████████████████████▎                  | 2.79G/4.94G [01:30<01:05, 32.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  57%|████████████████████████▎                  | 2.80G/4.94G [01:30<00:50, 42.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  53%|██████████████████████▉                    | 2.67G/5.00G [01:30<01:10, 32.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  58%|█████████████████████████                  | 2.65G/4.54G [01:30<00:47, 39.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  54%|███████████████████████                    | 2.68G/5.00G [01:30<01:01, 38.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  58%|█████████████████████████▏                 | 2.66G/4.54G [01:30<00:44, 42.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  57%|████████████████████████▍                  | 2.80G/4.94G [01:30<01:02, 34.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  57%|████████████████████████▍                  | 2.81G/4.94G [01:30<00:57, 37.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  59%|█████████████████████████▏                 | 2.66G/4.54G [01:30<00:59, 31.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  59%|█████████████████████████▎                 | 2.67G/4.54G [01:30<00:42, 43.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  57%|████████████████████████▍                  | 2.82G/4.94G [01:31<01:10, 30.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  57%|████████████████████████▌                  | 2.82G/4.94G [01:31<00:59, 35.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  57%|████████████████████████▌                  | 2.83G/4.94G [01:31<00:54, 38.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  59%|█████████████████████████▍                 | 2.68G/4.54G [01:31<00:48, 38.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  54%|███████████████████████▎                   | 2.71G/5.00G [01:31<01:26, 26.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  57%|████████████████████████▋                  | 2.83G/4.94G [01:31<01:22, 25.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  59%|█████████████████████████▍                 | 2.69G/4.54G [01:31<01:08, 27.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  59%|█████████████████████████▌                 | 2.70G/4.54G [01:31<00:42, 43.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  54%|███████████████████████▍                   | 2.72G/5.00G [01:31<01:08, 33.0MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  57%|████████████████████████▋                  | 2.84G/4.94G [01:32<01:44, 20.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  57%|████████████████████████▋                  | 2.84G/4.94G [01:32<01:57, 17.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  60%|█████████████████████████▋                 | 2.72G/4.54G [01:32<00:42, 42.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  57%|████████████████████████▋                  | 2.84G/4.94G [01:32<01:51, 18.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  58%|████████████████████████▊                  | 2.85G/4.94G [01:32<01:28, 23.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  55%|███████████████████████▋                   | 2.75G/5.00G [01:32<00:56, 39.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  60%|█████████████████████████▊                 | 2.72G/4.54G [01:32<00:53, 34.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  58%|████████████████████████▊                  | 2.85G/4.94G [01:32<01:59, 17.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  58%|████████████████████████▊                  | 2.86G/4.94G [01:32<01:27, 24.0MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  58%|████████████████████████▉                  | 2.86G/4.94G [01:33<01:11, 29.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  55%|███████████████████████▊                   | 2.77G/5.00G [01:33<00:55, 40.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  60%|█████████████████████████▉                 | 2.74G/4.54G [01:33<00:56, 31.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  58%|████████████████████████▉                  | 2.86G/4.94G [01:33<01:35, 21.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  58%|████████████████████████▉                  | 2.87G/4.94G [01:33<01:19, 26.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  58%|█████████████████████████                  | 2.88G/4.94G [01:33<01:04, 32.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  61%|██████████████████████████                 | 2.75G/4.54G [01:33<01:06, 26.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  61%|██████████████████████████▏                | 2.77G/4.54G [01:33<00:43, 40.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  58%|█████████████████████████                  | 2.88G/4.94G [01:33<01:26, 23.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  58%|█████████████████████████                  | 2.89G/4.94G [01:33<01:11, 28.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  58%|█████████████████████████▏                 | 2.89G/4.94G [01:34<01:03, 32.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  59%|█████████████████████████▏                 | 2.90G/4.94G [01:34<01:18, 26.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  59%|█████████████████████████▎                 | 2.90G/4.94G [01:34<01:00, 33.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  59%|█████████████████████████▎                 | 2.91G/4.94G [01:34<01:00, 33.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  56%|████████████████████████                   | 2.80G/5.00G [01:34<02:06, 17.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  59%|█████████████████████████▎                 | 2.91G/4.94G [01:34<01:17, 26.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  59%|█████████████████████████▍                 | 2.92G/4.94G [01:34<00:57, 35.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  62%|██████████████████████████▌                | 2.81G/4.54G [01:35<00:44, 38.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  59%|█████████████████████████▍                 | 2.92G/4.94G [01:35<00:57, 35.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  56%|████████████████████████▎                  | 2.82G/5.00G [01:35<01:20, 27.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  57%|████████████████████████▎                  | 2.83G/5.00G [01:35<00:59, 36.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  59%|█████████████████████████▍                 | 2.93G/4.94G [01:35<01:22, 24.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  59%|█████████████████████████▌                 | 2.94G/4.94G [01:35<01:09, 29.0MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  59%|█████████████████████████▌                 | 2.94G/4.94G [01:35<01:00, 33.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  57%|████████████████████████▍                  | 2.84G/5.00G [01:35<01:05, 33.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  62%|██████████████████████████▊                | 2.83G/4.54G [01:35<00:53, 31.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  60%|█████████████████████████▌                 | 2.94G/4.94G [01:36<01:29, 22.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  60%|█████████████████████████▋                 | 2.95G/4.94G [01:36<01:10, 28.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  60%|█████████████████████████▋                 | 2.96G/4.94G [01:36<01:00, 32.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  57%|████████████████████████▌                  | 2.86G/5.00G [01:36<00:55, 38.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  60%|█████████████████████████▋                 | 2.96G/4.94G [01:36<01:00, 32.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  63%|███████████████████████████                | 2.86G/4.54G [01:36<00:47, 35.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  57%|████████████████████████▋                  | 2.87G/5.00G [01:36<01:08, 31.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  60%|█████████████████████████▊                 | 2.97G/4.94G [01:36<01:00, 32.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  63%|███████████████████████████                | 2.86G/4.54G [01:36<01:04, 25.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  63%|███████████████████████████▎               | 2.88G/4.54G [01:36<00:39, 42.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  60%|█████████████████████████▉                 | 2.98G/4.94G [01:37<01:13, 26.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  60%|█████████████████████████▉                 | 2.98G/4.94G [01:37<00:59, 32.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  60%|██████████████████████████                 | 2.99G/4.94G [01:37<00:47, 41.3MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  64%|███████████████████████████▍               | 2.89G/4.54G [01:37<00:41, 39.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  58%|████████████████████████▉                  | 2.90G/5.00G [01:37<01:10, 29.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  61%|██████████████████████████                 | 2.99G/4.94G [01:37<01:08, 28.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  61%|██████████████████████████                 | 3.00G/4.94G [01:37<00:56, 34.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  61%|██████████████████████████▏                | 3.01G/4.94G [01:37<00:51, 37.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  64%|███████████████████████████▌               | 2.91G/4.54G [01:37<00:39, 41.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  58%|█████████████████████████                  | 2.92G/5.00G [01:37<01:00, 34.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  58%|█████████████████████████                  | 2.92G/5.00G [01:37<00:55, 37.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  61%|██████████████████████████▏                | 3.01G/4.94G [01:38<01:11, 27.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  61%|██████████████████████████▎                | 3.02G/4.94G [01:38<00:49, 38.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  59%|█████████████████████████▏                 | 2.93G/5.00G [01:38<01:14, 28.0MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  61%|██████████████████████████▍                | 3.04G/4.94G [01:38<00:43, 43.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  59%|█████████████████████████▎                 | 2.95G/5.00G [01:38<01:03, 32.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  62%|██████████████████████████▍                | 3.04G/4.94G [01:39<00:58, 32.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  62%|██████████████████████████▌                | 3.05G/4.94G [01:39<00:51, 36.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  65%|███████████████████████████▊               | 2.94G/4.54G [01:39<01:08, 23.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  59%|█████████████████████████▍                 | 2.96G/5.00G [01:39<00:59, 34.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  65%|███████████████████████████▊               | 2.94G/4.54G [01:39<01:01, 25.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  59%|█████████████████████████▌                 | 2.97G/5.00G [01:39<00:57, 35.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  62%|██████████████████████████▋                | 3.07G/4.94G [01:39<00:45, 40.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  65%|███████████████████████████▉               | 2.95G/4.54G [01:39<01:10, 22.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  65%|███████████████████████████▉               | 2.95G/4.54G [01:39<00:56, 27.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  60%|█████████████████████████▋                 | 2.98G/5.00G [01:39<01:03, 32.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  65%|████████████████████████████               | 2.96G/4.54G [01:39<00:48, 32.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  62%|██████████████████████████▊                | 3.08G/4.94G [01:40<00:44, 42.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  65%|████████████████████████████               | 2.96G/4.54G [01:40<00:59, 26.3MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  66%|████████████████████████████▏              | 2.97G/4.54G [01:40<00:39, 39.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  60%|█████████████████████████▋                 | 2.99G/5.00G [01:40<01:17, 25.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  63%|██████████████████████████▉                | 3.09G/4.94G [01:40<00:59, 31.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  63%|██████████████████████████▉                | 3.10G/4.94G [01:40<00:46, 39.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  66%|████████████████████████████▎              | 2.99G/4.54G [01:40<00:44, 35.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  60%|█████████████████████████▊                 | 3.01G/5.00G [01:40<01:03, 31.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  66%|████████████████████████████▎              | 2.99G/4.54G [01:40<00:39, 39.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  60%|█████████████████████████▉                 | 3.02G/5.00G [01:40<00:52, 37.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  63%|███████████████████████████                | 3.12G/4.94G [01:40<00:44, 41.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  66%|████████████████████████████▍              | 3.00G/4.54G [01:40<00:55, 27.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  61%|██████████████████████████                 | 3.03G/5.00G [01:41<01:00, 32.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  66%|████████████████████████████▍              | 3.00G/4.54G [01:41<00:41, 36.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  63%|███████████████████████████▏               | 3.13G/4.94G [01:41<00:45, 39.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  66%|████████████████████████████▌              | 3.01G/4.54G [01:41<00:55, 27.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  61%|██████████████████████████▏                | 3.04G/5.00G [01:41<01:03, 30.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  66%|████████████████████████████▌              | 3.02G/4.54G [01:41<00:43, 35.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  61%|██████████████████████████▏                | 3.05G/5.00G [01:41<00:52, 36.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  67%|████████████████████████████▌              | 3.02G/4.54G [01:41<00:39, 38.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  64%|███████████████████████████▍               | 3.15G/4.94G [01:41<00:45, 39.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  67%|████████████████████████████▋              | 3.03G/4.54G [01:41<00:53, 28.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  67%|████████████████████████████▊              | 3.04G/4.54G [01:42<00:35, 42.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  64%|███████████████████████████▍               | 3.15G/4.94G [01:42<00:55, 32.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  64%|███████████████████████████▍               | 3.16G/4.94G [01:42<00:50, 35.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  64%|███████████████████████████▌               | 3.16G/4.94G [01:42<00:44, 40.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  67%|████████████████████████████▊              | 3.04G/4.54G [01:42<00:46, 31.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  67%|████████████████████████████▉              | 3.05G/4.54G [01:42<00:37, 39.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  62%|██████████████████████████▍                | 3.08G/5.00G [01:42<01:04, 29.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  64%|███████████████████████████▋               | 3.18G/4.94G [01:42<00:45, 38.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  67%|████████████████████████████▉              | 3.06G/4.54G [01:42<00:49, 29.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  68%|█████████████████████████████              | 3.07G/4.54G [01:42<00:35, 41.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  62%|██████████████████████████▌                | 3.09G/5.00G [01:42<01:02, 30.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  64%|███████████████████████████▋               | 3.18G/4.94G [01:43<01:01, 28.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  65%|███████████████████████████▊               | 3.19G/4.94G [01:43<00:42, 40.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  68%|█████████████████████████████▏             | 3.08G/4.54G [01:43<00:38, 37.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  65%|███████████████████████████▊               | 3.20G/4.94G [01:43<00:55, 31.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  65%|███████████████████████████▉               | 3.21G/4.94G [01:43<00:45, 37.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  68%|█████████████████████████████▏             | 3.09G/4.54G [01:43<01:00, 24.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  65%|███████████████████████████▉               | 3.22G/4.94G [01:43<00:51, 33.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  65%|████████████████████████████               | 3.22G/4.94G [01:44<00:49, 34.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  65%|████████████████████████████               | 3.23G/4.94G [01:44<00:48, 35.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  65%|████████████████████████████               | 3.23G/4.94G [01:44<00:41, 41.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  68%|█████████████████████████████▍             | 3.11G/4.54G [01:44<00:50, 28.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  69%|█████████████████████████████▌             | 3.12G/4.54G [01:44<00:39, 36.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  65%|████████████████████████████▏              | 3.24G/4.94G [01:44<00:55, 30.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  66%|████████████████████████████▏              | 3.24G/4.94G [01:44<00:47, 35.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  66%|████████████████████████████▎              | 3.26G/4.94G [01:44<00:36, 46.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  63%|███████████████████████████▏               | 3.15G/5.00G [01:44<01:08, 26.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  63%|███████████████████████████▏               | 3.16G/5.00G [01:45<00:55, 33.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  69%|█████████████████████████████▌             | 3.12G/4.54G [01:45<01:07, 20.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  69%|█████████████████████████████▋             | 3.13G/4.54G [01:45<00:52, 26.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  66%|████████████████████████████▍              | 3.26G/4.94G [01:45<00:48, 34.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  66%|████████████████████████████▌              | 3.28G/4.94G [01:45<00:33, 49.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  63%|███████████████████████████▎               | 3.17G/5.00G [01:45<01:02, 29.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  64%|███████████████████████████▎               | 3.18G/5.00G [01:45<00:42, 42.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  69%|█████████████████████████████▋             | 3.14G/4.54G [01:45<00:51, 27.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  66%|████████████████████████████▌              | 3.29G/4.94G [01:45<00:50, 33.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  67%|████████████████████████████▋              | 3.30G/4.94G [01:45<00:37, 43.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  69%|█████████████████████████████▉             | 3.16G/4.54G [01:45<00:46, 29.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  64%|███████████████████████████▍               | 3.19G/5.00G [01:45<00:49, 36.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  67%|████████████████████████████▋              | 3.30G/4.94G [01:46<00:53, 30.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  64%|███████████████████████████▌               | 3.20G/5.00G [01:46<01:06, 27.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  67%|████████████████████████████▊              | 3.31G/4.94G [01:46<00:49, 33.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  64%|███████████████████████████▌               | 3.21G/5.00G [01:46<00:54, 32.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  70%|██████████████████████████████             | 3.18G/4.54G [01:46<00:37, 36.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  64%|███████████████████████████▌               | 3.21G/5.00G [01:46<00:52, 34.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  67%|████████████████████████████▉              | 3.32G/4.94G [01:46<00:40, 40.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  64%|███████████████████████████▋               | 3.22G/5.00G [01:46<01:06, 26.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  70%|██████████████████████████████▏            | 3.18G/4.54G [01:46<00:50, 27.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  65%|███████████████████████████▋               | 3.23G/5.00G [01:46<00:46, 37.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  70%|██████████████████████████████▏            | 3.19G/4.54G [01:47<00:37, 35.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  65%|███████████████████████████▊               | 3.23G/5.00G [01:47<00:42, 41.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  70%|██████████████████████████████▎            | 3.20G/4.54G [01:47<00:34, 38.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  71%|██████████████████████████████▎            | 3.20G/4.54G [01:47<00:45, 29.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  65%|███████████████████████████▊               | 3.24G/5.00G [01:47<01:02, 28.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  65%|███████████████████████████▉               | 3.24G/5.00G [01:47<00:53, 32.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  71%|██████████████████████████████▍            | 3.21G/4.54G [01:47<00:37, 35.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  65%|███████████████████████████▉               | 3.25G/5.00G [01:47<00:47, 36.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  71%|██████████████████████████████▍            | 3.22G/4.54G [01:47<00:34, 38.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  65%|███████████████████████████▉               | 3.25G/5.00G [01:47<01:00, 29.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  71%|██████████████████████████████▍            | 3.22G/4.54G [01:47<00:51, 25.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  65%|████████████████████████████               | 3.26G/5.00G [01:47<00:46, 37.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  71%|██████████████████████████████▌            | 3.23G/4.54G [01:48<00:43, 30.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  65%|████████████████████████████               | 3.26G/5.00G [01:48<01:01, 28.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  66%|████████████████████████████▏              | 3.28G/5.00G [01:48<00:41, 41.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  71%|██████████████████████████████▌            | 3.23G/4.54G [01:48<00:52, 25.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  71%|██████████████████████████████▋            | 3.24G/4.54G [01:48<00:31, 41.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  66%|████████████████████████████▏              | 3.28G/5.00G [01:48<00:54, 31.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  66%|████████████████████████████▎              | 3.29G/5.00G [01:48<00:39, 42.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  72%|██████████████████████████████▊            | 3.25G/4.54G [01:48<00:38, 33.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  72%|██████████████████████████████▊            | 3.26G/4.54G [01:48<00:30, 41.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  66%|████████████████████████████▎              | 3.30G/5.00G [01:49<00:50, 33.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  66%|████████████████████████████▍              | 3.31G/5.00G [01:49<00:38, 43.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  72%|██████████████████████████████▉            | 3.27G/4.54G [01:49<00:38, 32.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  72%|███████████████████████████████            | 3.28G/4.54G [01:49<00:30, 42.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  66%|████████████████████████████▌              | 3.31G/5.00G [01:49<00:51, 33.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  66%|████████████████████████████▌              | 3.32G/5.00G [01:49<00:38, 43.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  72%|███████████████████████████████            | 3.28G/4.54G [01:49<00:43, 29.3MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  73%|███████████████████████████████▏           | 3.29G/4.54G [01:49<00:28, 44.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  67%|████████████████████████████▋              | 3.33G/5.00G [01:49<00:50, 33.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  67%|████████████████████████████▋              | 3.34G/5.00G [01:50<00:41, 40.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  73%|███████████████████████████████▎           | 3.30G/4.54G [01:50<00:40, 30.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  67%|████████████████████████████▊              | 3.34G/5.00G [01:50<00:51, 32.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  73%|███████████████████████████████▎           | 3.31G/4.54G [01:50<00:31, 39.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  67%|████████████████████████████▊              | 3.35G/5.00G [01:50<00:43, 38.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  73%|███████████████████████████████▍           | 3.32G/4.54G [01:50<00:40, 30.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  73%|███████████████████████████████▌           | 3.33G/4.54G [01:50<00:30, 39.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  67%|████████████████████████████▉              | 3.36G/5.00G [01:50<00:54, 30.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  67%|████████████████████████████▉              | 3.37G/5.00G [01:50<00:40, 40.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  68%|█████████████████████████████              | 3.38G/5.00G [01:51<00:47, 34.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  73%|███████████████████████████████▌           | 3.33G/4.54G [01:51<00:40, 29.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  68%|█████████████████████████████              | 3.38G/5.00G [01:51<00:40, 39.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  74%|███████████████████████████████▋           | 3.34G/4.54G [01:51<00:37, 32.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  67%|█████████████████████████████              | 3.33G/4.94G [01:51<04:31, 5.93MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  74%|███████████████████████████████▋           | 3.34G/4.54G [01:51<00:48, 24.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  68%|█████████████████████████████▏             | 3.39G/5.00G [01:51<00:51, 31.3MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  74%|███████████████████████████████▊           | 3.35G/4.54G [01:51<00:35, 33.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  68%|█████████████████████████████              | 3.34G/4.94G [01:51<03:08, 8.50MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  74%|███████████████████████████████▊           | 3.36G/4.54G [01:51<00:33, 34.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  68%|█████████████████████████████▏             | 3.35G/4.94G [01:52<02:13, 11.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  74%|███████████████████████████████▊           | 3.36G/4.54G [01:52<00:44, 26.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  68%|█████████████████████████████▎             | 3.41G/5.00G [01:52<01:00, 26.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  74%|███████████████████████████████▉           | 3.37G/4.54G [01:52<00:34, 34.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  68%|█████████████████████████████▏             | 3.36G/4.94G [01:52<01:51, 14.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  68%|█████████████████████████████▎             | 3.37G/4.94G [01:52<01:11, 21.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  74%|███████████████████████████████▉           | 3.38G/4.54G [01:52<00:47, 24.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  68%|█████████████████████████████▍             | 3.42G/5.00G [01:52<01:06, 23.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  68%|█████████████████████████████▎             | 3.38G/4.94G [01:52<01:12, 21.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  68%|█████████████████████████████▍             | 3.38G/4.94G [01:53<01:00, 25.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  69%|█████████████████████████████▍             | 3.39G/4.94G [01:53<00:50, 30.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  75%|████████████████████████████████▏          | 3.40G/4.54G [01:53<00:37, 30.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  75%|████████████████████████████████▎          | 3.41G/4.54G [01:53<00:28, 40.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  69%|█████████████████████████████▌             | 3.39G/4.94G [01:53<01:03, 24.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  69%|█████████████████████████████▌             | 3.40G/4.94G [01:53<00:50, 30.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  69%|█████████████████████████████▌             | 3.40G/4.94G [01:53<00:42, 36.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  75%|████████████████████████████████▎          | 3.41G/4.54G [01:53<00:34, 33.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  75%|████████████████████████████████▍          | 3.42G/4.54G [01:53<00:29, 38.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  69%|█████████████████████████████▊             | 3.46G/5.00G [01:53<00:49, 31.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  69%|█████████████████████████████▊             | 3.47G/5.00G [01:53<00:36, 41.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  75%|████████████████████████████████▍          | 3.43G/4.54G [01:54<00:35, 31.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  76%|████████████████████████████████▌          | 3.44G/4.54G [01:54<00:23, 46.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  69%|█████████████████████████████▉             | 3.47G/5.00G [01:54<00:49, 30.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  69%|█████████████████████████████▋             | 3.42G/4.94G [01:54<01:02, 24.3MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  76%|████████████████████████████████▋          | 3.45G/4.54G [01:54<00:32, 33.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  76%|████████████████████████████████▋          | 3.45G/4.54G [01:54<00:25, 42.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  70%|██████████████████████████████             | 3.49G/5.00G [01:54<00:44, 33.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  69%|█████████████████████████████▊             | 3.42G/4.94G [01:54<01:04, 23.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  70%|█████████████████████████████▉             | 3.44G/4.94G [01:54<00:38, 39.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  76%|████████████████████████████████▊          | 3.46G/4.54G [01:55<00:36, 29.3MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  76%|████████████████████████████████▊          | 3.47G/4.54G [01:55<00:28, 38.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  70%|██████████████████████████████▏            | 3.51G/5.00G [01:55<00:48, 30.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  70%|█████████████████████████████▉             | 3.45G/4.94G [01:55<00:52, 28.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  70%|██████████████████████████████             | 3.46G/4.94G [01:55<00:52, 28.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  70%|██████████████████████████████▏            | 3.46G/4.94G [01:55<00:40, 36.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  70%|██████████████████████████████▏            | 3.47G/4.94G [01:55<00:35, 41.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  71%|██████████████████████████████▍            | 3.54G/5.00G [01:56<00:55, 26.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  77%|████████████████████████████████▉          | 3.48G/4.54G [01:56<01:05, 16.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  71%|██████████████████████████████▍            | 3.55G/5.00G [01:56<00:39, 37.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  70%|██████████████████████████████▏            | 3.48G/4.94G [01:56<01:00, 24.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  71%|██████████████████████████████▌            | 3.55G/5.00G [01:56<00:37, 38.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  71%|██████████████████████████████▎            | 3.49G/4.94G [01:56<00:43, 33.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  71%|██████████████████████████████▌            | 3.56G/5.00G [01:56<00:50, 28.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  77%|█████████████████████████████████          | 3.49G/4.54G [01:56<00:55, 19.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  71%|██████████████████████████████▋            | 3.56G/5.00G [01:56<00:36, 39.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  71%|██████████████████████████████▎            | 3.49G/4.94G [01:56<01:00, 24.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  71%|██████████████████████████████▍            | 3.50G/4.94G [01:57<00:47, 30.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  71%|██████████████████████████████▋            | 3.57G/5.00G [01:57<00:49, 29.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  72%|██████████████████████████████▊            | 3.58G/5.00G [01:57<00:33, 41.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  71%|██████████████████████████████▍            | 3.50G/4.94G [01:57<00:53, 27.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  71%|██████████████████████████████▌            | 3.51G/4.94G [01:57<00:41, 34.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  71%|██████████████████████████████▌            | 3.52G/4.94G [01:57<00:35, 39.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  72%|██████████████████████████████▊            | 3.59G/5.00G [01:57<00:48, 28.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  71%|██████████████████████████████▋            | 3.52G/4.94G [01:57<00:47, 29.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  71%|██████████████████████████████▋            | 3.53G/4.94G [01:57<00:34, 41.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  78%|█████████████████████████████████▍         | 3.53G/4.54G [01:58<00:41, 24.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  72%|██████████████████████████████▉            | 3.60G/5.00G [01:58<00:41, 33.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  78%|█████████████████████████████████▍         | 3.53G/4.54G [01:58<00:34, 29.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  72%|███████████████████████████████            | 3.61G/5.00G [01:58<00:37, 36.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  72%|██████████████████████████████▊            | 3.55G/4.94G [01:58<00:33, 41.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  72%|███████████████████████████████▏           | 3.62G/5.00G [01:58<00:41, 33.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  73%|███████████████████████████████▏           | 3.63G/5.00G [01:58<00:29, 45.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  72%|██████████████████████████████▉            | 3.56G/4.94G [01:58<00:35, 39.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  72%|███████████████████████████████            | 3.57G/4.94G [01:58<00:33, 41.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  78%|█████████████████████████████████▌         | 3.55G/4.54G [01:58<00:36, 26.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  73%|███████████████████████████████▎           | 3.64G/5.00G [01:58<00:40, 33.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  73%|███████████████████████████████▎           | 3.64G/5.00G [01:59<00:36, 37.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  72%|███████████████████████████████            | 3.57G/4.94G [01:59<00:47, 29.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  78%|█████████████████████████████████▋         | 3.56G/4.54G [01:59<00:32, 30.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  72%|███████████████████████████████            | 3.58G/4.94G [01:59<00:41, 32.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  79%|█████████████████████████████████▊         | 3.57G/4.54G [01:59<00:30, 31.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  72%|███████████████████████████████▏           | 3.58G/4.94G [01:59<00:40, 33.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  73%|███████████████████████████████▏           | 3.59G/4.94G [01:59<00:52, 26.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  73%|███████████████████████████████▏           | 3.59G/4.94G [01:59<00:42, 32.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  73%|███████████████████████████████▌           | 3.66G/5.00G [01:59<00:47, 28.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  73%|███████████████████████████████▎           | 3.60G/4.94G [01:59<00:39, 34.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  73%|███████████████████████████████▌           | 3.67G/5.00G [01:59<00:40, 32.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  79%|█████████████████████████████████▉         | 3.58G/4.54G [01:59<00:31, 30.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  73%|███████████████████████████████▌           | 3.67G/5.00G [02:00<00:39, 33.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  73%|███████████████████████████████▍           | 3.61G/4.94G [02:00<00:33, 39.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  79%|█████████████████████████████████▉         | 3.58G/4.54G [02:00<00:46, 20.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  74%|███████████████████████████████▋           | 3.68G/5.00G [02:00<00:44, 29.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  79%|██████████████████████████████████         | 3.59G/4.54G [02:00<00:31, 30.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  74%|███████████████████████████████▋           | 3.69G/5.00G [02:00<00:37, 35.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  73%|███████████████████████████████▍           | 3.62G/4.94G [02:00<00:41, 31.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  73%|███████████████████████████████▌           | 3.63G/4.94G [02:00<00:30, 43.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  74%|███████████████████████████████▊           | 3.70G/5.00G [02:00<00:47, 27.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  79%|██████████████████████████████████         | 3.60G/4.54G [02:00<00:40, 23.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  74%|███████████████████████████████▉           | 3.71G/5.00G [02:00<00:33, 38.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  74%|███████████████████████████████▌           | 3.63G/4.94G [02:01<00:45, 28.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  74%|███████████████████████████████▋           | 3.64G/4.94G [02:01<00:38, 34.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  74%|███████████████████████████████▉           | 3.71G/5.00G [02:01<00:45, 28.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  74%|████████████████████████████████           | 3.72G/5.00G [02:01<00:31, 41.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  74%|███████████████████████████████▋           | 3.65G/4.94G [02:01<00:44, 29.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  74%|███████████████████████████████▊           | 3.65G/4.94G [02:01<00:36, 35.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  75%|████████████████████████████████           | 3.73G/5.00G [02:01<00:43, 29.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  75%|████████████████████████████████▏          | 3.74G/5.00G [02:01<00:31, 40.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  80%|██████████████████████████████████▍        | 3.64G/4.54G [02:01<00:27, 32.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  74%|███████████████████████████████▊           | 3.66G/4.94G [02:02<00:44, 28.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  74%|███████████████████████████████▉           | 3.67G/4.94G [02:02<00:34, 36.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  74%|███████████████████████████████▉           | 3.68G/4.94G [02:02<00:32, 39.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  80%|██████████████████████████████████▌        | 3.65G/4.54G [02:02<00:35, 25.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  75%|████████████████████████████████▎          | 3.76G/5.00G [02:02<00:30, 40.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  75%|████████████████████████████████           | 3.68G/4.94G [02:02<00:41, 30.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  75%|████████████████████████████████           | 3.69G/4.94G [02:02<00:32, 38.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  75%|████████████████████████████████▍          | 3.77G/5.00G [02:02<00:35, 34.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  81%|██████████████████████████████████▋        | 3.66G/4.54G [02:02<00:32, 26.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  76%|████████████████████████████████▍          | 3.78G/5.00G [02:02<00:28, 42.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  75%|████████████████████████████████▏          | 3.70G/4.94G [02:03<00:32, 38.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  76%|████████████████████████████████▌          | 3.78G/5.00G [02:03<00:40, 29.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  76%|████████████████████████████████▌          | 3.79G/5.00G [02:03<00:28, 42.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  81%|██████████████████████████████████▊        | 3.68G/4.54G [02:03<00:29, 29.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  75%|████████████████████████████████▍          | 3.73G/4.94G [02:03<00:27, 44.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  76%|████████████████████████████████▋          | 3.80G/5.00G [02:03<00:37, 32.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  76%|████████████████████████████████▋          | 3.81G/5.00G [02:03<00:31, 38.3MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  82%|███████████████████████████████████        | 3.70G/4.54G [02:03<00:23, 35.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  76%|████████████████████████████████▍          | 3.73G/4.94G [02:03<00:36, 32.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  76%|████████████████████████████████▌          | 3.74G/4.94G [02:04<00:28, 42.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  76%|████████████████████████████████▊          | 3.82G/5.00G [02:04<00:33, 34.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  82%|███████████████████████████████████▏       | 3.71G/4.54G [02:04<00:25, 32.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  76%|████████████████████████████████▊          | 3.82G/5.00G [02:04<00:31, 37.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  76%|████████████████████████████████▋          | 3.75G/4.94G [02:04<00:29, 40.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  77%|████████████████████████████████▉          | 3.83G/5.00G [02:04<00:43, 26.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  82%|███████████████████████████████████▎       | 3.73G/4.54G [02:04<00:27, 29.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  77%|████████████████████████████████▉          | 3.83G/5.00G [02:04<00:30, 37.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  76%|████████████████████████████████▋          | 3.76G/4.94G [02:04<00:46, 25.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  76%|████████████████████████████████▊          | 3.77G/4.94G [02:05<00:36, 32.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  76%|████████████████████████████████▊          | 3.77G/4.94G [02:05<00:31, 36.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  82%|███████████████████████████████████▍       | 3.74G/4.54G [02:05<00:29, 27.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  77%|█████████████████████████████████          | 3.85G/5.00G [02:05<00:33, 34.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  83%|███████████████████████████████████▌       | 3.75G/4.54G [02:05<00:21, 36.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  77%|████████████████████████████████▉          | 3.79G/4.94G [02:05<00:29, 39.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  83%|███████████████████████████████████▌       | 3.76G/4.54G [02:05<00:27, 28.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  77%|█████████████████████████████████▏         | 3.86G/5.00G [02:05<00:43, 26.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  77%|█████████████████████████████████▎         | 3.87G/5.00G [02:05<00:31, 35.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  77%|█████████████████████████████████          | 3.81G/4.94G [02:06<00:28, 39.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  77%|█████████████████████████████████▎         | 3.87G/5.00G [02:06<00:42, 26.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  83%|███████████████████████████████████▋       | 3.77G/4.54G [02:06<00:33, 23.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  77%|█████████████████████████████████▏         | 3.82G/4.94G [02:06<00:28, 38.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  78%|█████████████████████████████████▍         | 3.89G/5.00G [02:06<00:43, 25.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  83%|███████████████████████████████████▋       | 3.77G/4.54G [02:06<00:50, 15.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  77%|█████████████████████████████████▎         | 3.83G/4.94G [02:06<00:31, 35.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  78%|█████████████████████████████████▌         | 3.90G/5.00G [02:06<00:37, 29.3MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  83%|███████████████████████████████████▊       | 3.78G/4.54G [02:07<01:02, 12.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  78%|█████████████████████████████████▋         | 3.91G/5.00G [02:07<00:27, 40.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  78%|█████████████████████████████████▍         | 3.84G/4.94G [02:07<00:35, 31.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  78%|█████████████████████████████████▍         | 3.84G/4.94G [02:07<00:33, 32.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  78%|█████████████████████████████████▍         | 3.85G/4.94G [02:07<00:31, 34.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  78%|█████████████████████████████████▋         | 3.92G/5.00G [02:07<00:35, 30.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  79%|█████████████████████████████████▊         | 3.93G/5.00G [02:07<00:23, 44.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  78%|█████████████████████████████████▌         | 3.86G/4.94G [02:07<00:37, 29.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  78%|█████████████████████████████████▌         | 3.86G/4.94G [02:07<00:28, 37.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  78%|█████████████████████████████████▋         | 3.87G/4.94G [02:07<00:24, 43.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  79%|█████████████████████████████████▉         | 3.95G/5.00G [02:07<00:26, 39.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  84%|████████████████████████████████████       | 3.81G/4.54G [02:08<00:26, 27.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  78%|█████████████████████████████████▋         | 3.88G/4.94G [02:08<00:31, 34.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  79%|█████████████████████████████████▊         | 3.88G/4.94G [02:08<00:28, 37.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  79%|█████████████████████████████████▉         | 3.95G/5.00G [02:08<00:38, 27.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  79%|██████████████████████████████████         | 3.96G/5.00G [02:08<00:26, 38.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  79%|█████████████████████████████████▊         | 3.89G/4.94G [02:08<00:34, 30.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  79%|█████████████████████████████████▊         | 3.89G/4.94G [02:08<00:30, 34.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  79%|█████████████████████████████████▉         | 3.90G/4.94G [02:08<00:25, 40.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  79%|██████████████████████████████████▏        | 3.97G/5.00G [02:08<00:36, 28.3MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  85%|████████████████████████████████████▍      | 3.84G/4.54G [02:08<00:21, 32.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  80%|██████████████████████████████████▏        | 3.98G/5.00G [02:08<00:31, 32.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  85%|████████████████████████████████████▍      | 3.85G/4.54G [02:09<00:18, 37.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  79%|█████████████████████████████████▉         | 3.90G/4.94G [02:09<00:36, 28.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  79%|██████████████████████████████████         | 3.92G/4.94G [02:09<00:23, 43.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  80%|██████████████████████████████████▎        | 3.99G/5.00G [02:09<00:36, 27.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  85%|████████████████████████████████████▌      | 3.86G/4.54G [02:09<00:23, 28.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  80%|██████████████████████████████████▎        | 3.99G/5.00G [02:09<00:30, 32.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  85%|████████████████████████████████████▌      | 3.87G/4.54G [02:09<00:19, 34.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  80%|██████████████████████████████████▎        | 4.00G/5.00G [02:09<00:27, 36.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  80%|██████████████████████████████████▏        | 3.93G/4.94G [02:09<00:26, 38.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  85%|████████████████████████████████████▋      | 3.88G/4.54G [02:09<00:21, 30.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  80%|██████████████████████████████████▍        | 4.00G/5.00G [02:09<00:40, 24.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  86%|████████████████████████████████████▊      | 3.89G/4.54G [02:09<00:14, 44.0MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  80%|██████████████████████████████████▎        | 3.94G/4.94G [02:10<00:31, 31.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  80%|██████████████████████████████████▎        | 3.95G/4.94G [02:10<00:27, 36.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  80%|██████████████████████████████████▎        | 3.95G/4.94G [02:10<00:26, 38.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  86%|████████████████████████████████████▉      | 3.90G/4.54G [02:10<00:18, 35.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  80%|██████████████████████████████████▍        | 3.96G/4.94G [02:10<00:33, 29.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  80%|██████████████████████████████████▍        | 3.96G/4.94G [02:10<00:26, 36.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  81%|██████████████████████████████████▋        | 4.03G/5.00G [02:10<00:29, 32.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  86%|████████████████████████████████████▉      | 3.90G/4.54G [02:10<00:24, 26.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  80%|██████████████████████████████████▌        | 3.97G/4.94G [02:11<00:36, 26.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  80%|██████████████████████████████████▌        | 3.98G/4.94G [02:11<00:28, 34.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  81%|██████████████████████████████████▋        | 4.04G/5.00G [02:11<00:31, 30.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  81%|██████████████████████████████████▋        | 3.98G/4.94G [02:11<00:24, 38.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  81%|██████████████████████████████████▊        | 4.04G/5.00G [02:11<00:30, 31.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  86%|█████████████████████████████████████▏     | 3.92G/4.54G [02:11<00:18, 32.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  81%|██████████████████████████████████▊        | 4.05G/5.00G [02:11<00:28, 33.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  81%|██████████████████████████████████▋        | 3.99G/4.94G [02:11<00:32, 29.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  81%|██████████████████████████████████▊        | 4.00G/4.94G [02:11<00:22, 41.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  87%|█████████████████████████████████████▎     | 3.94G/4.54G [02:11<00:19, 30.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  81%|██████████████████████████████████▊        | 4.06G/5.00G [02:11<00:32, 29.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  87%|█████████████████████████████████████▎     | 3.94G/4.54G [02:11<00:16, 35.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  81%|██████████████████████████████████▉        | 4.06G/5.00G [02:11<00:27, 34.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  81%|██████████████████████████████████▉        | 4.01G/4.94G [02:12<00:21, 42.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  81%|██████████████████████████████████▉        | 4.06G/5.00G [02:12<00:38, 24.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  87%|█████████████████████████████████████▍     | 3.95G/4.54G [02:12<00:20, 28.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  82%|███████████████████████████████████        | 4.07G/5.00G [02:12<00:23, 38.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  81%|██████████████████████████████████▉        | 4.02G/4.94G [02:12<00:25, 35.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  81%|███████████████████████████████████        | 4.02G/4.94G [02:12<00:24, 37.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  82%|███████████████████████████████████        | 4.03G/4.94G [02:12<00:21, 41.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  82%|███████████████████████████████████        | 4.08G/5.00G [02:12<00:35, 25.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  82%|███████████████████████████████████▏       | 4.09G/5.00G [02:12<00:22, 39.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  87%|█████████████████████████████████████▌     | 3.97G/4.54G [02:12<00:21, 26.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  88%|█████████████████████████████████████▋     | 3.98G/4.54G [02:12<00:14, 39.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  82%|███████████████████████████████████▏       | 4.10G/5.00G [02:13<00:28, 32.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  82%|███████████████████████████████████        | 4.04G/4.94G [02:13<00:45, 19.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  82%|███████████████████████████████████▏       | 4.04G/4.94G [02:13<00:33, 27.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  88%|█████████████████████████████████████▊     | 3.99G/4.54G [02:13<00:18, 30.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  82%|███████████████████████████████████▏       | 4.05G/4.94G [02:13<00:35, 25.0MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  82%|███████████████████████████████████▎       | 4.05G/4.94G [02:13<00:30, 29.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  88%|█████████████████████████████████████▉     | 4.00G/4.54G [02:13<00:20, 26.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  88%|█████████████████████████████████████▉     | 4.01G/4.54G [02:13<00:13, 39.0MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  82%|███████████████████████████████████▎       | 4.06G/4.94G [02:14<00:31, 27.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  82%|███████████████████████████████████▍       | 4.07G/4.94G [02:14<00:26, 33.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  82%|███████████████████████████████████▍       | 4.08G/4.94G [02:14<00:23, 36.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  89%|██████████████████████████████████████     | 4.02G/4.54G [02:14<00:16, 32.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  83%|███████████████████████████████████▋       | 4.14G/5.00G [02:14<00:31, 27.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  83%|███████████████████████████████████▌       | 4.09G/4.94G [02:14<00:27, 31.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  89%|██████████████████████████████████████▏    | 4.03G/4.54G [02:14<00:17, 29.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  83%|███████████████████████████████████▌       | 4.09G/4.94G [02:14<00:23, 35.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  89%|██████████████████████████████████████▎    | 4.04G/4.54G [02:14<00:12, 39.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  83%|███████████████████████████████████▊       | 4.16G/5.00G [02:14<00:28, 29.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  83%|███████████████████████████████████▋       | 4.10G/4.94G [02:15<00:30, 27.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  83%|███████████████████████████████████▋       | 4.11G/4.94G [02:15<00:21, 38.3MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  89%|██████████████████████████████████████▍    | 4.06G/4.54G [02:15<00:14, 34.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  83%|███████████████████████████████████▊       | 4.11G/4.94G [02:15<00:29, 28.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  83%|███████████████████████████████████▊       | 4.12G/4.94G [02:15<00:25, 32.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  83%|███████████████████████████████████▊       | 4.12G/4.94G [02:15<00:22, 36.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  90%|██████████████████████████████████████▌    | 4.07G/4.54G [02:15<00:13, 33.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  84%|████████████████████████████████████       | 4.14G/4.94G [02:16<00:17, 44.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  90%|██████████████████████████████████████▋    | 4.08G/4.54G [02:16<00:14, 31.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  84%|████████████████████████████████████       | 4.19G/5.00G [02:16<00:34, 23.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  90%|██████████████████████████████████████▋    | 4.09G/4.54G [02:16<00:13, 34.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  84%|████████████████████████████████████       | 4.20G/5.00G [02:16<00:29, 27.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  90%|██████████████████████████████████████▋    | 4.09G/4.54G [02:16<00:12, 36.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  84%|████████████████████████████████████       | 4.15G/4.94G [02:16<00:21, 37.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  90%|██████████████████████████████████████▊    | 4.10G/4.54G [02:16<00:17, 26.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  84%|████████████████████████████████████▏      | 4.21G/5.00G [02:16<00:30, 25.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  90%|██████████████████████████████████████▊    | 4.10G/4.54G [02:16<00:13, 33.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  84%|████████████████████████████████████▏      | 4.16G/4.94G [02:16<00:24, 32.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  90%|██████████████████████████████████████▉    | 4.11G/4.54G [02:16<00:12, 35.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  84%|████████████████████████████████████▏      | 4.16G/4.94G [02:16<00:23, 32.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  84%|████████████████████████████████████▎      | 4.17G/4.94G [02:17<00:22, 35.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  85%|████████████████████████████████████▎      | 4.23G/5.00G [02:17<00:26, 29.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  91%|██████████████████████████████████████▉    | 4.12G/4.54G [02:17<00:15, 27.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  85%|████████████████████████████████████▍      | 4.24G/5.00G [02:17<00:21, 35.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  84%|████████████████████████████████████▎      | 4.18G/4.94G [02:17<00:27, 27.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  91%|███████████████████████████████████████    | 4.13G/4.54G [02:17<00:10, 39.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  85%|████████████████████████████████████▍      | 4.19G/4.94G [02:17<00:19, 38.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  85%|████████████████████████████████████▍      | 4.19G/4.94G [02:17<00:18, 40.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  85%|████████████████████████████████████▌      | 4.25G/5.00G [02:17<00:17, 42.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  91%|███████████████████████████████████████▏   | 4.13G/4.54G [02:17<00:14, 28.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  91%|███████████████████████████████████████▏   | 4.14G/4.54G [02:17<00:11, 35.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  85%|████████████████████████████████████▋      | 4.26G/5.00G [02:17<00:22, 33.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  85%|████████████████████████████████████▌      | 4.20G/4.94G [02:18<00:36, 20.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  91%|███████████████████████████████████████▏   | 4.14G/4.54G [02:18<00:17, 22.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  86%|████████████████████████████████████▊      | 4.28G/5.00G [02:18<00:20, 35.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  91%|███████████████████████████████████████▎   | 4.15G/4.54G [02:18<00:13, 29.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  86%|████████████████████████████████████▊      | 4.28G/5.00G [02:18<00:18, 38.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  92%|███████████████████████████████████████▎   | 4.16G/4.54G [02:18<00:11, 33.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  85%|████████████████████████████████████▌      | 4.20G/4.94G [02:18<00:45, 16.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  92%|███████████████████████████████████████▍   | 4.16G/4.54G [02:18<00:14, 26.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  86%|████████████████████████████████████▉      | 4.29G/5.00G [02:18<00:23, 30.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  85%|████████████████████████████████████▌      | 4.20G/4.94G [02:18<00:47, 15.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  85%|████████████████████████████████████▌      | 4.21G/4.94G [02:19<00:42, 17.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  92%|███████████████████████████████████████▌   | 4.17G/4.54G [02:19<00:10, 34.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  86%|████████████████████████████████████▉      | 4.30G/5.00G [02:19<00:20, 33.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  85%|████████████████████████████████████▌      | 4.21G/4.94G [02:19<00:53, 13.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  86%|█████████████████████████████████████      | 4.30G/5.00G [02:19<00:28, 24.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  85%|████████████████████████████████████▋      | 4.21G/4.94G [02:19<00:41, 17.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  85%|████████████████████████████████████▋      | 4.22G/4.94G [02:19<00:35, 20.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  85%|████████████████████████████████████▋      | 4.22G/4.94G [02:19<00:28, 25.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  92%|███████████████████████████████████████▋   | 4.19G/4.54G [02:19<00:11, 29.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  93%|███████████████████████████████████████▊   | 4.20G/4.54G [02:19<00:08, 39.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  85%|████████████████████████████████████▋      | 4.22G/4.94G [02:20<00:41, 17.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  87%|█████████████████████████████████████▏     | 4.33G/5.00G [02:20<00:16, 39.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  86%|████████████████████████████████████▊      | 4.23G/4.94G [02:20<00:30, 23.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  86%|████████████████████████████████████▊      | 4.24G/4.94G [02:20<00:25, 28.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  93%|███████████████████████████████████████▉   | 4.22G/4.54G [02:20<00:08, 38.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  87%|█████████████████████████████████████▎     | 4.34G/5.00G [02:20<00:21, 30.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  87%|█████████████████████████████████████▎     | 4.34G/5.00G [02:20<00:17, 37.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  86%|████████████████████████████████████▉      | 4.24G/4.94G [02:20<00:35, 19.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  86%|████████████████████████████████████▉      | 4.25G/4.94G [02:20<00:26, 25.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  87%|█████████████████████████████████████▍     | 4.35G/5.00G [02:20<00:19, 32.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  86%|████████████████████████████████████▉      | 4.25G/4.94G [02:20<00:24, 28.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  86%|█████████████████████████████████████      | 4.25G/4.94G [02:20<00:20, 32.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  87%|█████████████████████████████████████▌     | 4.36G/5.00G [02:20<00:15, 41.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  93%|████████████████████████████████████████▏  | 4.25G/4.54G [02:21<00:08, 33.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  94%|████████████████████████████████████████▎  | 4.26G/4.54G [02:21<00:06, 46.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  86%|█████████████████████████████████████      | 4.26G/4.94G [02:21<00:28, 23.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  86%|█████████████████████████████████████      | 4.26G/4.94G [02:21<00:24, 28.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  86%|█████████████████████████████████████▏     | 4.27G/4.94G [02:21<00:19, 34.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  94%|████████████████████████████████████████▎  | 4.26G/4.54G [02:21<00:08, 30.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  94%|████████████████████████████████████████▍  | 4.27G/4.54G [02:21<00:06, 40.0MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  86%|█████████████████████████████████████▏     | 4.27G/4.94G [02:21<00:24, 26.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  87%|█████████████████████████████████████▎     | 4.28G/4.94G [02:21<00:18, 35.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  87%|█████████████████████████████████████▎     | 4.29G/4.94G [02:22<00:22, 28.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  87%|█████████████████████████████████████▎     | 4.30G/4.94G [02:22<00:17, 37.0MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  87%|█████████████████████████████████████▍     | 4.30G/4.94G [02:22<00:15, 41.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  87%|█████████████████████████████████████▍     | 4.31G/4.94G [02:22<00:19, 32.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  87%|█████████████████████████████████████▌     | 4.32G/4.94G [02:22<00:14, 43.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  88%|██████████████████████████████████████     | 4.42G/5.00G [02:22<00:17, 33.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  87%|█████████████████████████████████████▌     | 4.32G/4.94G [02:22<00:18, 32.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  88%|█████████████████████████████████████▋     | 4.33G/4.94G [02:23<00:16, 37.3MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  95%|████████████████████████████████████████▊  | 4.30G/4.54G [02:23<00:08, 29.0MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  88%|█████████████████████████████████████▋     | 4.33G/4.94G [02:23<00:14, 41.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  89%|██████████████████████████████████████▏    | 4.44G/5.00G [02:23<00:16, 34.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  95%|████████████████████████████████████████▊  | 4.31G/4.54G [02:23<00:08, 26.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  88%|█████████████████████████████████████▋     | 4.34G/4.94G [02:23<00:21, 27.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  88%|█████████████████████████████████████▊     | 4.35G/4.94G [02:23<00:16, 37.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  88%|█████████████████████████████████████▊     | 4.35G/4.94G [02:23<00:14, 39.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  89%|██████████████████████████████████████▎    | 4.46G/5.00G [02:23<00:13, 39.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  95%|████████████████████████████████████████▉  | 4.33G/4.54G [02:23<00:07, 30.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  88%|█████████████████████████████████████▉     | 4.36G/4.94G [02:24<00:19, 29.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  88%|█████████████████████████████████████▉     | 4.37G/4.94G [02:24<00:14, 40.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  89%|██████████████████████████████████████▍    | 4.47G/5.00G [02:24<00:15, 34.1MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  96%|█████████████████████████████████████████  | 4.34G/4.54G [02:24<00:07, 28.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  90%|██████████████████████████████████████▌    | 4.48G/5.00G [02:24<00:13, 39.2MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  96%|█████████████████████████████████████████  | 4.34G/4.54G [02:24<00:06, 32.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  89%|██████████████████████████████████████     | 4.38G/4.94G [02:24<00:15, 35.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  90%|██████████████████████████████████████▌    | 4.48G/5.00G [02:24<00:17, 29.7MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  96%|█████████████████████████████████████████▏ | 4.35G/4.54G [02:24<00:06, 28.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  90%|██████████████████████████████████████▋    | 4.49G/5.00G [02:24<00:12, 40.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  89%|██████████████████████████████████████▏    | 4.38G/4.94G [02:24<00:16, 33.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  89%|██████████████████████████████████████▏    | 4.39G/4.94G [02:24<00:14, 37.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  96%|█████████████████████████████████████████▎ | 4.37G/4.54G [02:24<00:04, 40.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  89%|██████████████████████████████████████▏    | 4.40G/4.94G [02:25<00:13, 41.8MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  90%|██████████████████████████████████████▋    | 4.50G/5.00G [02:25<00:13, 36.0MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  89%|██████████████████████████████████████▎    | 4.40G/4.94G [02:25<00:17, 30.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  89%|██████████████████████████████████████▎    | 4.41G/4.94G [02:25<00:15, 35.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  89%|██████████████████████████████████████▍    | 4.41G/4.94G [02:25<00:13, 39.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  97%|█████████████████████████████████████████▌ | 4.38G/4.54G [02:25<00:04, 35.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  89%|██████████████████████████████████████▍    | 4.42G/4.94G [02:25<00:17, 30.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  89%|██████████████████████████████████████▍    | 4.42G/4.94G [02:25<00:14, 35.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  97%|█████████████████████████████████████████▌ | 4.39G/4.54G [02:25<00:04, 30.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  90%|██████████████████████████████████████▌    | 4.43G/4.94G [02:25<00:12, 40.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  97%|█████████████████████████████████████████▋ | 4.40G/4.54G [02:26<00:04, 31.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  91%|██████████████████████████████████████▉    | 4.53G/5.00G [02:26<00:13, 33.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  90%|██████████████████████████████████████▋    | 4.44G/4.94G [02:26<00:12, 41.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  97%|█████████████████████████████████████████▋ | 4.40G/4.54G [02:26<00:07, 20.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  91%|███████████████████████████████████████    | 4.54G/5.00G [02:26<00:17, 26.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  97%|█████████████████████████████████████████▊ | 4.41G/4.54G [02:26<00:04, 30.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  91%|███████████████████████████████████████▏   | 4.55G/5.00G [02:26<00:12, 34.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  90%|██████████████████████████████████████▋    | 4.45G/4.94G [02:26<00:14, 33.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  90%|██████████████████████████████████████▊    | 4.45G/4.94G [02:26<00:14, 34.8MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  97%|█████████████████████████████████████████▊ | 4.42G/4.54G [02:26<00:04, 25.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  91%|███████████████████████████████████████▏   | 4.56G/5.00G [02:26<00:15, 28.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  97%|█████████████████████████████████████████▉ | 4.43G/4.54G [02:27<00:03, 34.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  90%|██████████████████████████████████████▊    | 4.46G/4.94G [02:27<00:15, 31.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  91%|██████████████████████████████████████▉    | 4.48G/4.94G [02:27<00:11, 40.5MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  98%|█████████████████████████████████████████▉ | 4.43G/4.54G [02:27<00:03, 28.3MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  98%|██████████████████████████████████████████ | 4.44G/4.54G [02:27<00:02, 36.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  92%|███████████████████████████████████████▎   | 4.58G/5.00G [02:27<00:15, 26.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  98%|██████████████████████████████████████████ | 4.45G/4.54G [02:27<00:02, 43.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  91%|███████████████████████████████████████    | 4.49G/4.94G [02:27<00:11, 39.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  98%|██████████████████████████████████████████▏| 4.45G/4.54G [02:27<00:02, 31.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  92%|███████████████████████████████████████▍   | 4.59G/5.00G [02:27<00:12, 32.0MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  98%|██████████████████████████████████████████▏| 4.46G/4.54G [02:27<00:02, 36.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  92%|███████████████████████████████████████▌   | 4.60G/5.00G [02:27<00:10, 37.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  92%|███████████████████████████████████████▌   | 4.60G/5.00G [02:28<00:10, 39.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  91%|███████████████████████████████████████    | 4.50G/4.94G [02:28<00:18, 24.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  91%|███████████████████████████████████████▏   | 4.50G/4.94G [02:28<00:15, 28.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  91%|███████████████████████████████████████▏   | 4.51G/4.94G [02:28<00:13, 32.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  92%|███████████████████████████████████████▋   | 4.61G/5.00G [02:28<00:16, 24.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  92%|███████████████████████████████████████▋   | 4.62G/5.00G [02:28<00:11, 34.3MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  99%|██████████████████████████████████████████▍| 4.48G/4.54G [02:28<00:01, 34.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  91%|███████████████████████████████████████▎   | 4.51G/4.94G [02:28<00:15, 27.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  91%|███████████████████████████████████████▎   | 4.52G/4.94G [02:28<00:13, 31.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  92%|███████████████████████████████████████▎   | 4.52G/4.94G [02:28<00:11, 36.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  93%|███████████████████████████████████████▊   | 4.63G/5.00G [02:29<00:13, 28.4MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  99%|██████████████████████████████████████████▌| 4.50G/4.54G [02:29<00:01, 32.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  93%|███████████████████████████████████████▊   | 4.64G/5.00G [02:29<00:10, 34.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  92%|███████████████████████████████████████▍   | 4.53G/4.94G [02:29<00:14, 28.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  92%|███████████████████████████████████████▍   | 4.54G/4.94G [02:29<00:10, 38.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  93%|███████████████████████████████████████▉   | 4.64G/5.00G [02:29<00:13, 26.6MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  93%|████████████████████████████████████████   | 4.65G/5.00G [02:29<00:08, 41.9MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  99%|██████████████████████████████████████████▋| 4.51G/4.54G [02:29<00:01, 27.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  92%|███████████████████████████████████████▋   | 4.56G/4.94G [02:29<00:09, 42.5MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  93%|████████████████████████████████████████   | 4.66G/5.00G [02:29<00:10, 31.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  93%|████████████████████████████████████████▏  | 4.67G/5.00G [02:30<00:08, 40.6MB/s]\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors: 100%|██████████████████████████████████████████▉| 4.53G/4.54G [02:30<00:00, 28.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  92%|███████████████████████████████████████▊   | 4.57G/4.94G [02:30<00:09, 40.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  93%|████████████████████████████████████████▏  | 4.67G/5.00G [02:30<00:09, 33.4MB/s]\n",
      "\n",
      "model-00003-of-00003.safetensors: 100%|███████████████████████████████████████████| 4.54G/4.54G [02:30<00:00, 30.2MB/s]\n",
      "model-00001-of-00003.safetensors:  93%|███████████████████████████████████████▉   | 4.59G/4.94G [02:30<00:07, 46.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  94%|████████████████████████████████████████▎  | 4.69G/5.00G [02:30<00:11, 27.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  93%|████████████████████████████████████████   | 4.61G/4.94G [02:31<00:07, 47.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  94%|████████████████████████████████████████▍  | 4.71G/5.00G [02:31<00:08, 33.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  93%|████████████████████████████████████████▏  | 4.61G/4.94G [02:31<00:11, 28.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  93%|████████████████████████████████████████▏  | 4.62G/4.94G [02:31<00:10, 31.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  94%|████████████████████████████████████████▏  | 4.62G/4.94G [02:31<00:09, 34.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  94%|████████████████████████████████████████▎  | 4.63G/4.94G [02:32<00:10, 30.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  94%|████████████████████████████████████████▎  | 4.63G/4.94G [02:32<00:08, 35.5MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  94%|████████████████████████████████████████▍  | 4.65G/4.94G [02:32<00:06, 42.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  95%|████████████████████████████████████████▊  | 4.75G/5.00G [02:32<00:09, 26.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  94%|████████████████████████████████████████▌  | 4.67G/4.94G [02:32<00:05, 47.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  95%|█████████████████████████████████████████  | 4.77G/5.00G [02:32<00:06, 33.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  95%|████████████████████████████████████████▋  | 4.68G/4.94G [02:33<00:05, 46.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  96%|█████████████████████████████████████████▏ | 4.78G/5.00G [02:33<00:06, 32.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  95%|████████████████████████████████████████▉  | 4.70G/4.94G [02:33<00:06, 40.1MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  96%|█████████████████████████████████████████▎ | 4.80G/5.00G [02:33<00:05, 35.1MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  95%|█████████████████████████████████████████  | 4.71G/4.94G [02:34<00:05, 42.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  96%|█████████████████████████████████████████▍ | 4.82G/5.00G [02:34<00:06, 29.6MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  96%|█████████████████████████████████████████▏ | 4.73G/4.94G [02:34<00:05, 39.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  97%|█████████████████████████████████████████▌ | 4.84G/5.00G [02:34<00:04, 36.0MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  96%|█████████████████████████████████████████▎ | 4.75G/4.94G [02:35<00:04, 45.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  97%|█████████████████████████████████████████▋ | 4.85G/5.00G [02:35<00:04, 30.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  96%|█████████████████████████████████████████▍ | 4.76G/4.94G [02:35<00:03, 48.4MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  97%|█████████████████████████████████████████▊ | 4.87G/5.00G [02:35<00:04, 30.9MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  97%|█████████████████████████████████████████▌ | 4.78G/4.94G [02:35<00:03, 42.9MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  98%|██████████████████████████████████████████ | 4.88G/5.00G [02:36<00:03, 34.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  97%|█████████████████████████████████████████▋ | 4.80G/4.94G [02:36<00:03, 42.7MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  97%|█████████████████████████████████████████▊ | 4.81G/4.94G [02:36<00:02, 47.3MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  98%|██████████████████████████████████████████▏| 4.91G/5.00G [02:36<00:02, 34.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  98%|██████████████████████████████████████████ | 4.83G/4.94G [02:37<00:02, 50.7MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  99%|██████████████████████████████████████████▍| 4.93G/5.00G [02:37<00:01, 39.4MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  98%|██████████████████████████████████████████ | 4.84G/4.94G [02:37<00:02, 39.8MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  98%|██████████████████████████████████████████▎| 4.86G/4.94G [02:37<00:01, 45.2MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors:  99%|██████████████████████████████████████████▋| 4.96G/5.00G [02:37<00:01, 32.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  99%|██████████████████████████████████████████▍| 4.88G/4.94G [02:38<00:01, 40.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  99%|██████████████████████████████████████████▌| 4.89G/4.94G [02:38<00:01, 42.3MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  99%|██████████████████████████████████████████▌| 4.89G/4.94G [02:38<00:01, 45.2MB/s]\n",
      "\n",
      "model-00001-of-00003.safetensors:  99%|██████████████████████████████████████████▋| 4.91G/4.94G [02:39<00:00, 49.0MB/s]\n",
      "\n",
      "model-00002-of-00003.safetensors: 100%|███████████████████████████████████████████| 5.00G/5.00G [02:39<00:00, 31.4MB/s]\n",
      "model-00001-of-00003.safetensors: 100%|███████████████████████████████████████████| 4.94G/4.94G [02:40<00:00, 30.9MB/s]\n",
      "\n",
      "Upload 3 LFS files: 100%|████████████████████████████████████████████████████████████████| 3/3 [02:40<00:00, 53.53s/it]\n",
      "C:\\Users\\201902452\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\201902452\\.cache\\huggingface\\hub\\models--MrFat--mistral7b_medic-v0.2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/MrFat/mistral7b_medic-v0.2/commit/f2615b4b8538fb2a321a9c79385ae7190287e5be', commit_message='Upload tokenizer', commit_description='', oid='f2615b4b8538fb2a321a9c79385ae7190287e5be', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"MrFat/mistral7b_medic-v0.2\") #Path\n",
    "tokenizer.push_to_hub(\"MrFat/mistral7b_medic-v0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e91779-14c0-4bd8-b121-7ed41fa05eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.model.push_to_hub(\"MrFat/mistral7b_medic\")\n",
    "#tokenizer.push_to_hub(\"MrFat/mistral7b_medic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306c1ce5-fdd3-44ed-b8ad-98a8ee3d8f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51562cd5-03a5-492a-8338-629a77e3302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# A PARTIR DE AQUI, EL MODELO YA HA SIDO FINE-TUNEADO ########################\n",
    "\n",
    "# Inference test\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "model_hf = \"MrFat/mistral7b_medic\"\n",
    "\n",
    "tokenizer_hf = AutoTokenizer.from_pretrained(\n",
    "    model_hf,\n",
    "    trust_remote_code=True,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer_hf.pad_token = tokenizer_hf.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1afe3cde-5fbb-4125-88e5-11a0203557bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 3/3 [00:06<00:00,  2.11s/it]\n"
     ]
    }
   ],
   "source": [
    "bnb_config_hf = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "base_model_hf = AutoModelForCausalLM.from_pretrained(\n",
    "    model_hf,\n",
    "    quantization_config=bnb_config_hf,\n",
    "    device_map = \"auto\",\n",
    "    trust_remote_code=True,\n",
    "    token=\"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\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83826361-beb0-4d0e-9204-295bc94b8d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the medical treatment for an infection caused by Baylisascaris? \n",
      " Great question! There is no specific medical treatment for Baylisascaris infections. The treatment for Baylisascaris infection is supportive care. The patient is given fluids and nutrients to maintain hydration and nutrition. The patient may be given medications to control seizures, fever, and pain. The patient may be given medications to prevent or treat complications such as pneumonia, liver damage, and kidney damage. The patient may be given medications to prevent or treat infections caused by other organisms. The patient may be given medications to prevent or treat complications such as pneumonia, liver damage, and kidney damage. The patient may be given medications to prevent or treat complications such as pneumonia, liver damage, and kidney damage. The patient may be given medications to prevent or treat complications such as pneumonia, liver damage, and kidney damage. The patient may be given medications to prevent or treat complications such as pneumonia, liver damage, and kidney damage. The patient may be given medications to prevent or treat complications such as pneumonia, liver damage, and kidney damage. The patient may be given medications to prevent or treat complications such as pneumonia, liver damage, and kidney damage. The patient may be given medications to prevent or treat complications such as pneumonia, liver damage, and kidney damage. The patient may be given medications to prevent or treat complications such as pneumonia, liver damage, and kidney damage. The patient may be given medications to prevent or treat complications such as pneumonia, liver damage, and kidney damage. The patient may be given medications to prevent or treat complications such as pneumonia, liver damage, and kidney damage. The patient may be given medications to prevent or treat complications such as pneumonia, liver damage, and kidney damage. The patient may be given medications to prevent or treat complications such as pneumonia, liver damage, and kidney damage. The patient may be given medications to prevent or treat complications such as pneumonia, liver damage, and kidney damage. The patient may be given medications to prevent or treat complications such as pneumonia, liver damage, and kidney damage. The patient may be given medications to prevent or treat complications such as pneumonia, liver damage, and kidney damage. The patient may be given medications to prevent or treat complications such\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"\"\"What is the medical treatment for an infection caused by Baylisascaris? \\n\"\"\"\n",
    "\n",
    "# CUDA: Para programar directamente la GPU\n",
    "model_input = tokenizer_hf(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "base_model_hf.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer_hf.decode(base_model_hf.generate(**model_input, max_new_tokens=512, pad_token_id=2)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1893bd5a-5b12-4be2-b7ac-9e277ec4171b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2128e3ac-cc40-4368-a7c4-c2bf96b93410",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pag 20, 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12737bb4-8284-4112-b619-1b975a071974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7295ca4c-a190-4586-9dd1-4bbb99f35ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df09bde-549c-44fa-915e-c10cb62878d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921faf22-a762-4d16-bf4f-81b95cd9f6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eae5868-4ead-4c21-85fa-8495456d801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_response(\"### Instruction:\\nUse the provided input to create an instruction that could have been used to generate the response with an LLM.### Input:\\nThe first thing to know is that guacamole is a popular dip made from avocados, tomatoes, onions, and spices. It originated in Mexico, and is generally eaten as an appetizer or snack. Here are some simple steps: Choose 2 ripe avocados, about 2 cups Mash avocados in a large bowl using a fork or potato masher Add in 1-2 chopped tomatoes, salt, pepper, 1-2 garlic cloves, minced, 1-2 teaspoons fresh lime juice, and 1⁄4-1⁄2 cup chopped cilantro (optional). Let sit for about 10 minutes Taste, and add more salt, pepper, cilantro, or lime juice if needed Guacamole is usually served with tortilla chips. There are many variations, such as adding sour cream, diced vegetables, or more spicy hot peppers.\\n\\n### Response:\", merged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f309d5ef-bd08-42b8-8eef-92c045767137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3fbcd5a-918e-450c-95ba-d500bd03c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m tensorboard.main --logdir=resultados/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0019dcdc-8333-4641-a079-d643fefe0822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74094edb-5d73-4870-99b5-e4767dd66cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49901d8-bd3a-42c0-b188-de96c0093f48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cc5207-02c6-409b-a81b-6d2294604387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b2f31b-9716-4c99-93ab-71747006367b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b652cc8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec730fbc-7b9a-4268-9900-36712043566e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\201902452\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\utils\\modeling.py:1363: UserWarning: Current model requires 536875008 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  3.71it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 13\u001b[0m\n\u001b[0;32m      3\u001b[0m pipe \u001b[38;5;241m=\u001b[39m pipeline(\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     model \u001b[38;5;241m=\u001b[39m fine_tuned_model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     device_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the medical treatment for an infection caused by Baylisascaris?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 13\u001b[0m sequences \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m<s>[INST] \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprompt\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m [/INST]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(sequences[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\text_generation.py:240\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[1;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(chats, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1242\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m   1235\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[0;32m   1236\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1239\u001b[0m         )\n\u001b[0;32m   1240\u001b[0m     )\n\u001b[0;32m   1241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1249\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1248\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1249\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1250\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1149\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1148\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1149\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1150\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\text_generation.py:327\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[1;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[0;32m    324\u001b[0m         generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prefix_length\n\u001b[0;32m    326\u001b[0m \u001b[38;5;66;03m# BS x SL\u001b[39;00m\n\u001b[1;32m--> 327\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m out_b \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1622\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1614\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   1615\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1616\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   1617\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   1618\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1619\u001b[0m     )\n\u001b[0;32m   1621\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[1;32m-> 1622\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1623\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1629\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1631\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1634\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1636\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH:\n\u001b[0;32m   1637\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   1638\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   1639\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1640\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1645\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[0;32m   1646\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:2791\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   2788\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   2790\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 2791\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2792\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2794\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2795\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2796\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   2799\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:1158\u001b[0m, in \u001b[0;36mMistralForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1155\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m   1157\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m-> 1158\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1165\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1166\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1168\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1170\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1171\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:1043\u001b[0m, in \u001b[0;36mMistralModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1033\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m   1034\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m   1035\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1040\u001b[0m         use_cache,\n\u001b[0;32m   1041\u001b[0m     )\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1043\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1044\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1052\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:770\u001b[0m, in \u001b[0;36mMistralDecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[0;32m    768\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m    769\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[1;32m--> 770\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    771\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[0;32m    773\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:179\u001b[0m, in \u001b[0;36mMistralMLP.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdown_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Pipeline function from Transformers library to generate response based on the prompt\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model = fine_tuned_model,\n",
    "    tokenizer = tokenizer,\n",
    "    torch_dtype = torch.bfloat16,\n",
    "    device_map = \"auto\"\n",
    ")\n",
    "\n",
    "prompt = \"What is the medical treatment for an infection caused by Baylisascaris?\"\n",
    "\n",
    "sequences = pipe(\n",
    "    f\"<s>[INST] {prompt} [/INST]\",\n",
    "    do_sample = True,\n",
    "    max_new_tokens = 250,\n",
    "    temperature = 0.7,\n",
    "    top_k = 50,\n",
    "    top_p = 0.95,\n",
    "    num_return_sequences = 1,\n",
    ")\n",
    "print(sequences[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf09885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7d61e2-5995-49a0-b8b2-5bbf1f86573f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e33182d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62364f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fff63f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6689dfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 3/3 [00:11<00:00,  3.72s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Mistral, same as before\n",
    "    quantization_config=bnb_config,  # Same quantization config as before\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    token=\"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\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a6feed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(base_model, \"mistral7b_medic\") #output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce047119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond(query):\n",
    "    eval_prompt = \"\"\"Patient's Query:\\n\\n {} ###\\n\\n\"\"\".format(query)\n",
    "    model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    output = ft_model.generate(input_ids=model_input[\"input_ids\"].to(\"cuda\"),\n",
    "                           attention_mask=model_input[\"attention_mask\"], \n",
    "                           max_new_tokens=512, repetition_penalty=1.15)\n",
    "    result = tokenizer.decode(output[0], skip_special_tokens=True).replace(eval_prompt, \"\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0e38c04-4297-4c8b-ba9f-0f3a768fb513",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'respond' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mrespond\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat does a soy allergy mean?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'respond' is not defined"
     ]
    }
   ],
   "source": [
    "result = respond(\"What does a soy allergy mean?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90481f3d-4ed6-4029-b26a-eb5237dd0638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Doctor's Answer:\n",
      "\n",
      " Soy allergies are common food allergies. They can cause symptoms ranging from mild to severe, including hives, swelling of the face and throat, difficulty breathing, vomiting, diarrhea, stomach pain, and anaphylaxis (a potentially life-threatening condition). Symptoms usually appear within minutes to hours after eating foods containing soy. If you suspect that you or someone in your family has a soy allergy, it is important to see a doctor for proper diagnosis and treatment. The only way to prevent a reaction is to avoid all sources of soy. This may include reading labels carefully when shopping for food, avoiding restaurants where cross contamination with soy is possible, and carrying an emergency epinephrine auto-injector at all times.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da29621-b597-4a63-8525-d6c9d670a6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
